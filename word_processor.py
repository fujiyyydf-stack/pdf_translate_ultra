#!/usr/bin/env python3
"""
Word æ–‡æ¡£å¤„ç†æ¨¡å—
åŠŸèƒ½ï¼šè¯»å–ã€è§£æ Word æ–‡æ¡£ï¼Œæå–æ®µè½æ–‡æœ¬
"""

import re
from pathlib import Path
from typing import List, Dict, Optional

try:
    from docx import Document
    from docx.shared import Pt
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    print("è­¦å‘Š: python-docx æœªå®‰è£…ï¼ŒWord æ–‡ä»¶å¤„ç†åŠŸèƒ½å°†ä¸å¯ç”¨")
    print("è¯·è¿è¡Œ: pip install python-docx")


# æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
SUPPORTED_FORMATS = ['.docx']


def is_supported_word_file(filepath: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„ Word æ–‡ä»¶æ ¼å¼"""
    return Path(filepath).suffix.lower() in SUPPORTED_FORMATS


class WordProcessor:
    """Word æ–‡æ¡£å¤„ç†å™¨"""
    
    def __init__(self):
        if not DOCX_AVAILABLE:
            raise ImportError("python-docx æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install python-docx")
    
    def extract_paragraphs(self, docx_path: str) -> List[Dict]:
        """
        ä» Word æ–‡æ¡£æå–æ®µè½
        
        Args:
            docx_path: Word æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ®µè½åˆ—è¡¨ [{"index": 0, "text": "...", "style": "Normal", ...}]
        """
        doc = Document(docx_path)
        paragraphs = []
        
        for i, para in enumerate(doc.paragraphs):
            text = para.text.strip()
            if text:  # å¿½ç•¥ç©ºæ®µè½
                paragraphs.append({
                    "index": i,
                    "text": text,
                    "style": para.style.name if para.style else "Normal",
                    "is_heading": para.style and "Heading" in para.style.name if para.style else False,
                    "char_count": len(text)
                })
        
        return paragraphs
    
    def extract_with_formatting(self, docx_path: str) -> List[Dict]:
        """
        æå–æ®µè½ï¼Œä¿ç•™æ›´å¤šæ ¼å¼ä¿¡æ¯ï¼ˆç”¨äºç²¾ç¡®åŒ¹é…ï¼‰
        
        Args:
            docx_path: Word æ–‡ä»¶è·¯å¾„
            
        Returns:
            å¸¦æ ¼å¼ä¿¡æ¯çš„æ®µè½åˆ—è¡¨
        """
        doc = Document(docx_path)
        paragraphs = []
        
        for i, para in enumerate(doc.paragraphs):
            text = para.text.strip()
            if not text:
                continue
            
            # æ£€æµ‹æ ¼å¼ç‰¹å¾
            is_bold = any(run.bold for run in para.runs if run.bold)
            is_italic = any(run.italic for run in para.runs if run.italic)
            
            # æ£€æµ‹æ˜¯å¦ä¸ºæ ‡é¢˜
            is_heading = False
            heading_level = 0
            if para.style:
                style_name = para.style.name
                is_heading = "Heading" in style_name or "æ ‡é¢˜" in style_name
                # æå–æ ‡é¢˜çº§åˆ«
                level_match = re.search(r'(\d+)', style_name)
                if level_match:
                    heading_level = int(level_match.group(1))
            
            paragraphs.append({
                "index": i,
                "text": text,
                "style": para.style.name if para.style else "Normal",
                "is_heading": is_heading,
                "heading_level": heading_level,
                "is_bold": is_bold,
                "is_italic": is_italic,
                "char_count": len(text),
                "word_count": len(text.split())
            })
        
        return paragraphs
    
    def extract_by_sections(self, docx_path: str) -> List[Dict]:
        """
        æŒ‰ç« èŠ‚æå–æ–‡æœ¬ï¼ˆé€‚ç”¨äºæœ‰æ˜ç¡®ç« èŠ‚ç»“æ„çš„æ–‡æ¡£ï¼‰
        
        Returns:
            ç« èŠ‚åˆ—è¡¨ [{"title": "...", "level": 1, "paragraphs": [...]}]
        """
        paragraphs = self.extract_with_formatting(docx_path)
        
        sections = []
        current_section = {
            "title": "å¼€ç¯‡",
            "level": 0,
            "paragraphs": []
        }
        
        for para in paragraphs:
            if para["is_heading"]:
                # ä¿å­˜å½“å‰ç« èŠ‚
                if current_section["paragraphs"]:
                    sections.append(current_section)
                
                # å¼€å§‹æ–°ç« èŠ‚
                current_section = {
                    "title": para["text"],
                    "level": para["heading_level"],
                    "paragraphs": []
                }
            else:
                current_section["paragraphs"].append(para)
        
        # ä¿å­˜æœ€åä¸€ä¸ªç« èŠ‚
        if current_section["paragraphs"]:
            sections.append(current_section)
        
        return sections
    
    def merge_short_paragraphs(
        self, 
        paragraphs: List[Dict], 
        min_length: int = 50
    ) -> List[Dict]:
        """
        åˆå¹¶è¿‡çŸ­çš„æ®µè½ï¼ˆå¯èƒ½æ˜¯è¢«é”™è¯¯åˆ†å‰²çš„ï¼‰
        
        Args:
            paragraphs: æ®µè½åˆ—è¡¨
            min_length: æœ€å°é•¿åº¦é˜ˆå€¼
            
        Returns:
            åˆå¹¶åçš„æ®µè½åˆ—è¡¨
        """
        if not paragraphs:
            return []
        
        merged = []
        buffer = None
        
        for para in paragraphs:
            # æ ‡é¢˜ä¸åˆå¹¶
            if para.get("is_heading"):
                if buffer:
                    merged.append(buffer)
                    buffer = None
                merged.append(para)
                continue
            
            if buffer is None:
                buffer = para.copy()
            elif len(buffer["text"]) < min_length:
                # åˆå¹¶åˆ° buffer
                buffer["text"] += "\n" + para["text"]
                buffer["char_count"] = len(buffer["text"])
            else:
                merged.append(buffer)
                buffer = para.copy()
        
        if buffer:
            merged.append(buffer)
        
        # é‡æ–°ç¼–å·
        for i, para in enumerate(merged):
            para["merged_index"] = i
        
        return merged
    
    def get_document_stats(self, docx_path: str) -> Dict:
        """
        è·å–æ–‡æ¡£ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        paragraphs = self.extract_paragraphs(docx_path)
        
        total_chars = sum(p["char_count"] for p in paragraphs)
        total_words = sum(len(p["text"].split()) for p in paragraphs)
        heading_count = sum(1 for p in paragraphs if p.get("is_heading"))
        
        return {
            "total_paragraphs": len(paragraphs),
            "total_characters": total_chars,
            "total_words": total_words,
            "heading_count": heading_count,
            "avg_paragraph_length": total_chars // len(paragraphs) if paragraphs else 0
        }
    
    def extract_text_only(self, docx_path: str) -> str:
        """
        æå–çº¯æ–‡æœ¬ï¼ˆç”¨äºç®€å•åœºæ™¯ï¼‰
        
        Returns:
            å®Œæ•´æ–‡æœ¬å­—ç¬¦ä¸²
        """
        doc = Document(docx_path)
        texts = []
        
        for para in doc.paragraphs:
            text = para.text.strip()
            if text:
                texts.append(text)
        
        return "\n\n".join(texts)


def test_word_processor():
    """æµ‹è¯•å‡½æ•°"""
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python word_processor.py <word_file.docx>")
        return
    
    filepath = sys.argv[1]
    
    if not Path(filepath).exists():
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        return
    
    processor = WordProcessor()
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = processor.get_document_stats(filepath)
    print("\nğŸ“Š æ–‡æ¡£ç»Ÿè®¡:")
    print(f"  æ®µè½æ•°: {stats['total_paragraphs']}")
    print(f"  å­—ç¬¦æ•°: {stats['total_characters']}")
    print(f"  æ ‡é¢˜æ•°: {stats['heading_count']}")
    print(f"  å¹³å‡æ®µè½é•¿åº¦: {stats['avg_paragraph_length']}")
    
    # æå–æ®µè½
    paragraphs = processor.extract_with_formatting(filepath)
    print(f"\nğŸ“ å‰ 5 ä¸ªæ®µè½:")
    for para in paragraphs[:5]:
        text_preview = para["text"][:50] + "..." if len(para["text"]) > 50 else para["text"]
        print(f"  [{para['index']}] {para['style']}: {text_preview}")


if __name__ == "__main__":
    test_word_processor()
