#!/usr/bin/env python3
"""
ç¼–è¾‘æœåŠ¡æ ¸å¿ƒæ¨¡å—
åŠŸèƒ½ï¼šæ•´åˆç¿»è¯‘ä¸ç¼–è¾‘å®¡æ ¡åŠŸèƒ½ï¼Œæ‰“ç£¨ç”¨æˆ·è¯‘æ–‡
"""

import os
import json
import time
import threading
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Optional, Callable

from openai import OpenAI
from dotenv import load_dotenv

from word_processor import WordProcessor
from text_aligner import TextAligner

load_dotenv()


class EditorService:
    """ç¼–è¾‘æœåŠ¡ - å¯¹æ¯”ã€è¯„å®¡ã€æ‰“ç£¨è¯‘æ–‡"""
    
    # ç¼–è¾‘å®¡æ ¡é»˜è®¤æç¤ºè¯
    DEFAULT_EDITOR_PROMPT = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç¿»è¯‘ç¼–è¾‘ï¼ŒåŒæ—¶ç²¾é€šæ³•è¯­å’Œä¸­æ–‡ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„å‡ºç‰ˆç¼–è¾‘ç»éªŒã€‚

ä½ å°†æ”¶åˆ°ï¼š
1. æ³•è¯­åŸæ–‡
2. ç”¨æˆ·è‡ªå·±çš„ä¸­æ–‡è¯‘æ–‡ï¼ˆåˆç¨¿ï¼‰
3. å¤šä¸ª AI æ¨¡å‹çš„ç¿»è¯‘ç‰ˆæœ¬

## ä½ çš„è§’è‰²

ä½ åŒæ—¶æ‹…ä»»ä¸¤ä¸ªè§’è‰²ï¼š

### è§’è‰²1ï¼šç¿»è¯‘è€…
- ç‹¬ç«‹ç†è§£åŸæ–‡ï¼Œåˆ¤æ–­å„è¯‘æ–‡çš„å‡†ç¡®æ€§
- è¯†åˆ«ç¿»è¯‘ä¸­çš„é”™è¯¯ï¼ˆæ¼è¯‘ã€è¯¯è¯‘ã€è¿‡è¯‘ï¼‰

### è§’è‰²2ï¼šä¸¥å‰çš„ç¼–è¾‘
- ä»¥å‡ºç‰ˆæ ‡å‡†å®¡è§†è¯‘æ–‡è´¨é‡
- æ£€æŸ¥æœ¯è¯­å‡†ç¡®æ€§ã€è¡Œæ–‡æµç•…åº¦ã€é£æ ¼ä¸€è‡´æ€§
- ç»™å‡ºå…·ä½“çš„ä¿®æ”¹å»ºè®®

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰

```
[è¯„å®¡æ„è§]
å¯¹ç”¨æˆ·è¯‘æ–‡çš„ç®€è¦è¯„ä»·ï¼š
- ä¼˜ç‚¹ï¼šï¼ˆ1-2 å¥ï¼‰
- é—®é¢˜ï¼šï¼ˆåˆ—å‡ºä¸»è¦é—®é¢˜ï¼Œå¦‚æœ‰ï¼‰
- å‚è€ƒï¼šï¼ˆè¯´æ˜ä» AI è¯‘æ–‡ä¸­å€Ÿé‰´äº†ä»€ä¹ˆï¼Œå¦‚æœ‰ï¼‰

[æœ€ç»ˆè¯‘æ–‡]
æ‰“ç£¨åçš„æœ€ä½³è¯‘æ–‡
```

## ç¼–è¾‘åŸåˆ™

1. **å¿ å®åŸæ–‡**ï¼šä¸å¾—æ“…è‡ªå¢åˆ å†…å®¹
2. **å°Šé‡ä½œè€…**ï¼šä¿ç•™ç”¨æˆ·è¯‘æ–‡çš„ä¼˜ç§€è¡¨è¾¾
3. **å–é•¿è¡¥çŸ­**ï¼šç»¼åˆå„ç‰ˆæœ¬ä¼˜ç‚¹
4. **ç²¾ç›Šæ±‚ç²¾**ï¼šæ¯ä¸ªè¯è¯­éƒ½è¦åå¤æ¨æ•²
5. **æœ¯è¯­ä¸€è‡´**ï¼šä¿æŒä¸“ä¸šæœ¯è¯­ç¿»è¯‘çš„ä¸€è‡´æ€§
6. **æ ¼å¼æ¸…ç†**ï¼šåˆ é™¤æ®‹ç•™çš„æ°´å°ã€é¡µç ã€æ–‡ä»¶åç­‰æ— å…³å†…å®¹
"""

    # ç¿»è¯‘å¯¹æ¯”æç¤ºè¯
    DEFAULT_TRANSLATION_PROMPT = """ä½ æ˜¯ä¸€ä½ç²¾é€šæ³•è¯­å’Œä¸­æ–‡çš„ä¸“ä¸šç¿»è¯‘å®˜ã€‚
è¯·å°†ä»¥ä¸‹æ³•è¯­æ–‡æœ¬ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚

è¦æ±‚ï¼š
1. å‡†ç¡®ä¼ è¾¾åŸæ„ï¼Œè¯­è¨€æµç•…è‡ªç„¶
2. ä¿æŒå­¦æœ¯æ€§/æ–‡å­¦æ€§é£æ ¼
3. ä¸“ä¸šæœ¯è¯­åå¯åŠ æ‹¬å·æ ‡æ³¨åŸæ–‡
4. ç›´æ¥è¿”å›è¯‘æ–‡ï¼Œä¸è¦è§£é‡Š
"""

    # æ— ç”¨æˆ·è¯‘æ–‡æ—¶çš„æ•´åˆæç¤ºè¯
    DEFAULT_INTEGRATION_PROMPT = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç¿»è¯‘å®¡æ ¡ä¸“å®¶ï¼Œç²¾é€šæ³•è¯­å’Œä¸­æ–‡ã€‚

ä½ å°†æ”¶åˆ°ï¼š
1. æ³•è¯­åŸæ–‡
2. å¤šä¸ª AI æ¨¡å‹çš„ç¿»è¯‘ç‰ˆæœ¬

è¯·æ•´åˆå‡ºæœ€ä¼˜ç¿»è¯‘ã€‚

## è¾“å‡ºæ ¼å¼

```
[åˆ†æ]
ç®€è¦è¯´æ˜å–èˆä¾æ®

[è¯‘æ–‡]
æœ€ç»ˆæ•´åˆçš„è¯‘æ–‡
```
"""

    def __init__(
        self,
        api_key: str = None,
        base_url: str = None,
        translation_models: List = None,  # æ”¯æŒå­—ç¬¦ä¸²åˆ—è¡¨æˆ–æ¨¡å‹é…ç½®åˆ—è¡¨
        editor_model = None,              # æ”¯æŒå­—ç¬¦ä¸²æˆ–æ¨¡å‹é…ç½®
        editor_prompt: str = None,
        translation_prompts: List[str] = None,
        alignment_model = None,           # æ”¯æŒå­—ç¬¦ä¸²æˆ–æ¨¡å‹é…ç½®
        use_smart_alignment: bool = True,
        output_dir: str = "output"
    ):
        """
        åˆå§‹åŒ–ç¼–è¾‘æœåŠ¡
        
        Args:
            api_key: é»˜è®¤ API å¯†é’¥
            base_url: é»˜è®¤ API åŸºç¡€ URL
            translation_models: ç”¨äºå¯¹æ¯”ç¿»è¯‘çš„æ¨¡å‹åˆ—è¡¨ï¼Œæ”¯æŒä¸¤ç§æ ¼å¼ï¼š
                - å­—ç¬¦ä¸²åˆ—è¡¨: ["model1", "model2"]
                - é…ç½®åˆ—è¡¨: [{"model": "doubao-1.5-pro", "base_url": "...", "api_key": "..."}, ...]
            editor_model: ç”¨äºç¼–è¾‘å®¡æ ¡çš„æ¨¡å‹ï¼Œæ”¯æŒå­—ç¬¦ä¸²æˆ–é…ç½®å­—å…¸
            editor_prompt: è‡ªå®šä¹‰ç¼–è¾‘æç¤ºè¯
            translation_prompts: æ¯ä¸ªç¿»è¯‘æ¨¡å‹çš„æç¤ºè¯
            alignment_model: ç”¨äºæ®µè½å¯¹é½çš„æ¨¡å‹ï¼Œæ”¯æŒå­—ç¬¦ä¸²æˆ–é…ç½®å­—å…¸
            use_smart_alignment: æ˜¯å¦ä½¿ç”¨æ™ºèƒ½å¯¹é½ï¼ˆå¤§æ¨¡å‹ï¼‰
            output_dir: è¾“å‡ºç›®å½•
        """
        # é»˜è®¤é…ç½®
        self.default_api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.default_base_url = base_url or os.getenv("OPENAI_BASE_URL")
        
        # è§£ææ¨¡å‹é…ç½®
        self.translation_model_configs = self._parse_model_configs(
            translation_models or ["x-ai/grok-4.1-fast", "x-ai/grok-4.1-fast"]
        )
        self.editor_model_config = self._parse_single_model_config(
            editor_model or "x-ai/grok-4.1-fast"
        )
        self.alignment_model_config = self._parse_single_model_config(
            alignment_model or "x-ai/grok-4.1-fast"
        )
        
        self.use_smart_alignment = use_smart_alignment
        self.editor_prompt = editor_prompt or self.DEFAULT_EDITOR_PROMPT
        
        # æ¯ä¸ªç¿»è¯‘æ¨¡å‹çš„æç¤ºè¯
        if translation_prompts and len(translation_prompts) >= len(self.translation_model_configs):
            self.translation_prompts = translation_prompts
        else:
            self.translation_prompts = [self.DEFAULT_TRANSLATION_PROMPT] * len(self.translation_model_configs)
        
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ç¼“å­˜ API å®¢æˆ·ç«¯ {(base_url, api_key): client}
        self._client_cache = {}
        
        # åˆå§‹åŒ–å­æ¨¡å—
        self.word_processor = WordProcessor()
        
        # å¯¹é½å™¨ä½¿ç”¨å¯¹é½æ¨¡å‹çš„é…ç½®
        align_config = self.alignment_model_config
        self.text_aligner = TextAligner(
            api_key=align_config.get("api_key", self.default_api_key),
            base_url=align_config.get("base_url", self.default_base_url),
            alignment_model=align_config["model"]
        )
    
    def _parse_single_model_config(self, model_config) -> dict:
        """è§£æå•ä¸ªæ¨¡å‹é…ç½®"""
        if isinstance(model_config, str):
            return {
                "model": model_config,
                "base_url": self.default_base_url,
                "api_key": self.default_api_key
            }
        elif isinstance(model_config, dict):
            return {
                "model": model_config.get("model", "x-ai/grok-4.1-fast"),
                "base_url": model_config.get("base_url", self.default_base_url),
                "api_key": model_config.get("api_key", self.default_api_key),
                "name": model_config.get("name", model_config.get("model", "unknown"))
            }
        else:
            return {
                "model": "x-ai/grok-4.1-fast",
                "base_url": self.default_base_url,
                "api_key": self.default_api_key
            }
    
    def _parse_model_configs(self, models: List) -> List[dict]:
        """è§£ææ¨¡å‹é…ç½®åˆ—è¡¨"""
        configs = []
        for m in models:
            configs.append(self._parse_single_model_config(m))
        return configs
    
    def _get_client(self, base_url: str = None, api_key: str = None) -> OpenAI:
        """è·å–æˆ–åˆ›å»º API å®¢æˆ·ç«¯ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        url = base_url or self.default_base_url
        key = api_key or self.default_api_key
        
        cache_key = (url, key)
        if cache_key not in self._client_cache:
            client_kwargs = {"api_key": key}
            if url:
                client_kwargs["base_url"] = url
            self._client_cache[cache_key] = OpenAI(**client_kwargs)
        
        return self._client_cache[cache_key]
    
    # å…¼å®¹æ—§å±æ€§
    @property
    def translation_models(self):
        return [c["model"] for c in self.translation_model_configs]
    
    @property
    def editor_model(self):
        return self.editor_model_config["model"]
    
    @property
    def alignment_model(self):
        return self.alignment_model_config["model"]
    
    @property
    def client(self):
        """é»˜è®¤å®¢æˆ·ç«¯ï¼ˆç”¨äºç¼–è¾‘æ¨¡å‹ï¼‰"""
        config = self.editor_model_config
        return self._get_client(config.get("base_url"), config.get("api_key"))
    
    def _call_model_with_config(
        self, 
        model_config: dict,
        system_prompt: str, 
        user_content: str,
        max_retries: int = 3
    ) -> str:
        """
        ä½¿ç”¨æŒ‡å®šé…ç½®è°ƒç”¨æ¨¡å‹ API
        
        Args:
            model_config: {"model": "...", "base_url": "...", "api_key": "..."}
        """
        client = self._get_client(
            model_config.get("base_url"),
            model_config.get("api_key")
        )
        model = model_config.get("model")
        
        for attempt in range(max_retries):
            try:
                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_content}
                    ],
                    temperature=0.3,
                    max_tokens=4000
                )
                result = response.choices[0].message.content
                if result and result.strip():
                    return result.strip()
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)
                else:
                    raise e
        return ""
    
    def _call_model(
        self, 
        model: str, 
        system_prompt: str, 
        user_content: str,
        max_retries: int = 3
    ) -> str:
        """è°ƒç”¨æ¨¡å‹ APIï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼Œå…¼å®¹æ—§ä»£ç ï¼‰"""
        config = {
            "model": model,
            "base_url": self.default_base_url,
            "api_key": self.default_api_key
        }
        return self._call_model_with_config(config, system_prompt, user_content, max_retries)

    def translate_for_comparison(self, source_text: str) -> Dict[str, str]:
        """
        è°ƒç”¨å¤šä¸ªæ¨¡å‹ç¿»è¯‘ï¼Œç”¨äºå¯¹æ¯”
        æ¯ä¸ªæ¨¡å‹å¯ä»¥æœ‰ä¸åŒçš„ URL å’Œ API Key
        
        Returns:
            {model_key: translation}
        """
        translations = {}
        
        with ThreadPoolExecutor(max_workers=len(self.translation_model_configs)) as executor:
            futures = {}
            for idx, model_config in enumerate(self.translation_model_configs):
                prompt = self.translation_prompts[idx] if idx < len(self.translation_prompts) \
                    else self.DEFAULT_TRANSLATION_PROMPT
                
                # è·å–æ˜¾ç¤ºåç§°
                display_name = model_config.get("name", model_config.get("model", "unknown"))
                
                future = executor.submit(
                    self._call_model_with_config, 
                    model_config,
                    prompt, 
                    f"è¯·ç¿»è¯‘ä»¥ä¸‹æ³•è¯­æ–‡æœ¬ï¼š\n\n{source_text}"
                )
                # ä½¿ç”¨åºå·+æ˜¾ç¤ºåç§°ä½œä¸ºkey
                futures[future] = f"{idx+1}_{display_name}"
            
            for future in as_completed(futures):
                key = futures[future]
                try:
                    translations[key] = future.result()
                except Exception as e:
                    translations[key] = f"[ç¿»è¯‘å¤±è´¥: {str(e)}]"
        
        return translations
    
    def edit_paragraph(
        self, 
        source_text: str,           # åŸæ–‡
        user_translation: str,      # ç”¨æˆ·è¯‘æ–‡ï¼ˆå¯ä»¥æ˜¯å¤šä¸ªè¯‘æ–‡åˆå¹¶çš„ï¼‰
        ai_translations: Dict[str, str] = None,  # AI å¯¹æ¯”è¯‘æ–‡ï¼ˆå¯é€‰ï¼‰
        alignment_info: Dict = None  # å¯¹é½ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œç”¨äºå±•ç¤ºå¤æ‚æƒ…å†µï¼‰
    ) -> Dict:
        """
        ç¼–è¾‘å®¡æ ¡å•ä¸ªæ®µè½
        
        Args:
            source_text: æ³•è¯­åŸæ–‡
            user_translation: ç”¨æˆ·çš„è¯‘æ–‡ï¼ˆå¯èƒ½æ˜¯å¤šä¸ªè¯‘æ–‡åˆå¹¶ï¼‰
            ai_translations: AI ç¿»è¯‘ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼Œè‹¥æ— åˆ™è°ƒç”¨è·å–ï¼‰
            alignment_info: å¯¹é½å…ƒä¿¡æ¯ï¼ŒåŒ…å«é‡å ã€å¤šè¯‘æ–‡ç­‰æƒ…å†µ
            
        Returns:
            {
                "review": "è¯„å®¡æ„è§",
                "final": "æœ€ç»ˆè¯‘æ–‡",
                "ai_translations": {...}
            }
        """
        # å¦‚æœæ²¡æœ‰ AI è¯‘æ–‡ï¼Œå…ˆè·å–
        if ai_translations is None:
            ai_translations = self.translate_for_comparison(source_text)
        
        # æ„å»ºç¼–è¾‘è¯·æ±‚
        user_content = f"""## æ³•è¯­åŸæ–‡

{source_text}

## ç”¨æˆ·è¯‘æ–‡ï¼ˆå¾…å®¡æ ¡ï¼‰

{user_translation}"""

        # å¦‚æœæœ‰å¯¹é½ä¿¡æ¯ï¼Œæ·»åŠ è¯´æ˜
        if alignment_info:
            coverage = alignment_info.get("coverage", "")
            is_multi = alignment_info.get("is_multi_target", False)
            note = alignment_info.get("alignment_note", "")
            
            if is_multi or coverage == "overlap":
                user_content += f"\n\nâš ï¸ æ³¨æ„ï¼šæ­¤åŸæ–‡å¯¹åº”å¤šä¸ªè¯‘æ–‡æ®µè½"
                if note:
                    user_content += f"ï¼ˆ{note}ï¼‰"
                user_content += "ï¼Œä¸Šæ–¹çš„ç”¨æˆ·è¯‘æ–‡æ˜¯åˆå¹¶åçš„å†…å®¹ï¼Œè¯·ç‰¹åˆ«æ³¨æ„è¿è´¯æ€§å’Œå®Œæ•´æ€§ã€‚"

        user_content += "\n\n## AI å‚è€ƒè¯‘æ–‡\n\n"
        for model, trans in sorted(ai_translations.items()):
            # ä»keyä¸­æå–æ˜¾ç¤ºå
            model_display = model.split("_", 1)[-1] if "_" in model else model
            model_short = model_display.split("/")[-1] if "/" in model_display else model_display
            user_content += f"### {model_short}\n{trans}\n\n"
        
        user_content += "## è¯·æŒ‰æ ¼å¼è¾“å‡ºè¯„å®¡æ„è§å’Œæœ€ç»ˆè¯‘æ–‡"
        
        # è°ƒç”¨ç¼–è¾‘æ¨¡å‹ï¼ˆä½¿ç”¨ç¼–è¾‘æ¨¡å‹çš„ç‹¬ç«‹é…ç½®ï¼‰
        result = self._call_model_with_config(self.editor_model_config, self.editor_prompt, user_content)
        
        # è§£æç»“æœ
        review = ""
        final_text = result
        
        if "[è¯„å®¡æ„è§]" in result and "[æœ€ç»ˆè¯‘æ–‡]" in result:
            parts = result.split("[æœ€ç»ˆè¯‘æ–‡]")
            if len(parts) == 2:
                review = parts[0].replace("[è¯„å®¡æ„è§]", "").strip()
                final_text = parts[1].strip()
                # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
                final_text = final_text.replace("```", "").strip()
        
        return {
            "source": source_text,
            "user_translation": user_translation,
            "ai_translations": ai_translations,
            "review": review,
            "final": final_text
        }
    
    def translate_and_integrate(
        self,
        source_text: str,
        ai_translations: Dict[str, str] = None
    ) -> Dict:
        """
        æ— ç”¨æˆ·è¯‘æ–‡æ—¶ï¼Œä»…ç¿»è¯‘å¹¶æ•´åˆ
        
        Returns:
            {
                "ai_translations": {...},
                "review": "æ•´åˆåˆ†æ",
                "final": "æœ€ç»ˆè¯‘æ–‡"
            }
        """
        if ai_translations is None:
            ai_translations = self.translate_for_comparison(source_text)
        
        # æ„å»ºæ•´åˆè¯·æ±‚
        user_content = f"""## æ³•è¯­åŸæ–‡

{source_text}

## AI ç¿»è¯‘ç‰ˆæœ¬

"""
        for model, trans in sorted(ai_translations.items()):
            model_display = model.split("_", 1)[-1] if "_" in model else model
            model_short = model_display.split("/")[-1] if "/" in model_display else model_display
            user_content += f"### {model_short}\n{trans}\n\n"
        
        user_content += "## è¯·æŒ‰æ ¼å¼è¾“å‡ºåˆ†æå’Œæ•´åˆè¯‘æ–‡"
        
        # ä½¿ç”¨ç¼–è¾‘æ¨¡å‹çš„ç‹¬ç«‹é…ç½®
        result = self._call_model_with_config(
            self.editor_model_config,
            self.DEFAULT_INTEGRATION_PROMPT,
            user_content
        )
        
        # è§£æç»“æœ
        review = ""
        final_text = result
        
        if "[åˆ†æ]" in result and "[è¯‘æ–‡]" in result:
            parts = result.split("[è¯‘æ–‡]")
            if len(parts) == 2:
                review = parts[0].replace("[åˆ†æ]", "").strip()
                final_text = parts[1].strip()
                final_text = final_text.replace("```", "").strip()
        
        return {
            "ai_translations": ai_translations,
            "review": review,
            "final": final_text
        }
    
    def process_document(
        self,
        pdf_path: str,
        word_path: str,
        start_page: int = None,
        end_page: int = None,
        max_workers: int = 5,
        progress_callback: Callable[[int, int], None] = None
    ) -> Dict:
        """
        å¤„ç†å®Œæ•´æ–‡æ¡£ï¼šå¯¹é½ã€ç¿»è¯‘ã€ç¼–è¾‘
        
        Args:
            pdf_path: PDF åŸæ–‡è·¯å¾„
            word_path: Word è¯‘æ–‡è·¯å¾„
            start_page: èµ·å§‹é¡µç 
            end_page: ç»“æŸé¡µç 
            max_workers: å¹¶å‘æ•°
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (completed, total)
            
        Returns:
            å¤„ç†ç»“æœ
        """
        results = {
            "paragraphs": [],
            "stats": {
                "total": 0,
                "matched": 0,
                "edited": 0,
                "translated_only": 0,
                "overlap": 0,       # é‡å è¦†ç›–çš„æ®µè½æ•°
                "missing": 0,       # æ¼è¯‘çš„æ®µè½æ•°
                "multi_target": 0,  # å¯¹åº”å¤šä¸ªè¯‘æ–‡çš„æ®µè½æ•°
                "skipped": 0        # è·³è¿‡çš„æ®µè½æ•°ï¼ˆå‡ºç‰ˆä¿¡æ¯ç­‰ï¼‰
            }
        }
        
        # 1. æå– PDF åŸæ–‡
        from pdf_translator import PDFTranslator
        pdf_helper = PDFTranslator(api_key="dummy", base_url="dummy")
        pdf_pages = pdf_helper.extract_text_from_pdf(pdf_path)
        
        # ç­›é€‰é¡µé¢èŒƒå›´
        if start_page or end_page:
            pdf_pages = [
                p for p in pdf_pages
                if (start_page is None or p["page"] >= start_page) and
                   (end_page is None or p["page"] <= end_page)
            ]
        
        # è½¬æ¢ä¸ºæ®µè½åˆ—è¡¨
        pdf_paragraphs = []
        for page_data in pdf_pages:
            page_num = page_data["page"]
            text = page_data["text"]
            # æŒ‰æ®µè½åˆ†å‰²
            for para in text.split("\n\n"):
                para = para.strip()
                if para and len(para) > 10:  # è¿‡æ»¤è¿‡çŸ­å†…å®¹
                    pdf_paragraphs.append({
                        "page": page_num,
                        "text": para,
                        "index": len(pdf_paragraphs)
                    })
        
        print(f"ğŸ“„ æå– PDF æ®µè½: {len(pdf_paragraphs)} ä¸ª")
        
        # 2. æå– Word è¯‘æ–‡
        word_paragraphs = self.word_processor.extract_paragraphs(word_path)
        print(f"ğŸ“ æå– Word æ®µè½: {len(word_paragraphs)} ä¸ª")
        
        # 3. æ™ºèƒ½å¯¹é½æ®µè½
        print(f"ğŸ¤– ä½¿ç”¨{'æ™ºèƒ½' if self.use_smart_alignment else 'è§„åˆ™'}å¯¹é½...")
        
        if self.use_smart_alignment:
            aligned = self.text_aligner.smart_align(pdf_paragraphs, word_paragraphs)
        else:
            aligned = self.text_aligner.align_paragraphs(pdf_paragraphs, word_paragraphs)
        
        # æ‰“å°å¯¹é½è´¨é‡
        quality = self.text_aligner.calculate_alignment_quality(aligned)
        print(f"ğŸ”— å¯¹é½å®Œæˆ: åŒ¹é…ç‡ {quality['match_rate']:.1%}, å¹³å‡ç½®ä¿¡åº¦ {quality['average_confidence']:.2f}")
        
        # ç»Ÿè®¡å„ç§å¯¹é½æƒ…å†µ
        missing_count = 0
        overlap_count = 0
        multi_target_count = 0
        skipped_count = 0
        
        for a in aligned:
            coverage = a.get("coverage", "")
            if coverage == "skip":
                skipped_count += 1
            elif coverage == "missing" or not a.get("matched"):
                missing_count += 1
            if coverage == "overlap":
                overlap_count += 1
            if a.get("is_multi_target"):
                multi_target_count += 1
        
        # æ‰“å°è¯¦ç»†ç»Ÿè®¡
        if skipped_count > 0:
            print(f"â­ï¸ æœ‰ {skipped_count} ä¸ªåŸæ–‡æ®µè½è·³è¿‡ï¼ˆå‡ºç‰ˆä¿¡æ¯ç­‰ï¼‰")
        if missing_count > 0:
            print(f"âš ï¸ æœ‰ {missing_count} ä¸ªåŸæ–‡æ®µè½æ²¡æœ‰æ‰¾åˆ°å¯¹åº”è¯‘æ–‡ï¼ˆæ¼è¯‘ï¼‰")
        if overlap_count > 0:
            print(f"ğŸ”€ æœ‰ {overlap_count} ä¸ªåŸæ–‡æ®µè½è¢«å¤šä¸ªè¯‘æ–‡é‡å è¦†ç›–")
        if multi_target_count > 0:
            print(f"ğŸ“‘ æœ‰ {multi_target_count} ä¸ªåŸæ–‡æ®µè½å¯¹åº”å¤šä¸ªè¯‘æ–‡æ®µè½")
        
        results["stats"]["total"] = len(aligned)
        results["stats"]["matched"] = quality["matched_paragraphs"]
        results["stats"]["missing"] = missing_count
        results["stats"]["overlap"] = overlap_count
        results["stats"]["multi_target"] = multi_target_count
        results["stats"]["skipped"] = skipped_count
        
        # 4. å¹¶å‘å¤„ç†æ¯ä¸ªæ®µè½
        lock = threading.Lock()
        processed = 0
        processed_results = []
        
        def process_paragraph(item):
            nonlocal processed
            
            source_text = item["source_text"]
            user_trans = item["target_text"] if item["matched"] else None
            coverage = item.get("coverage", "")
            
            # æå–å¯¹é½ä¿¡æ¯ç”¨äºç¼–è¾‘æç¤º
            alignment_info = {
                "coverage": coverage,
                "is_multi_target": item.get("is_multi_target", False),
                "alignment_note": item.get("alignment_note", ""),
                "target_indices": item.get("target_indices", [])
            }
            
            # è·³è¿‡ä¸éœ€è¦ç¿»è¯‘çš„å†…å®¹ï¼ˆå‡ºç‰ˆä¿¡æ¯ç­‰ï¼‰
            if coverage == "skip":
                result = {
                    **item,
                    "ai_translations": {},
                    "review": "â­ï¸ æ­¤æ®µä¸ºå‡ºç‰ˆä¿¡æ¯/é¡µçœ‰é¡µè„šï¼Œæ— éœ€ç¿»è¯‘",
                    "final": "",  # ä¸è¾“å‡º
                    "edited": False,
                    "has_user_translation": False,
                    "skipped": True
                }
                with lock:
                    processed += 1
                    if progress_callback:
                        progress_callback(processed, len(aligned))
                return result
            
            try:
                # è·å– AI ç¿»è¯‘
                ai_trans = self.translate_for_comparison(source_text)
                
                if user_trans:
                    # æœ‰ç”¨æˆ·è¯‘æ–‡ï¼Œè¿›è¡Œç¼–è¾‘å®¡æ ¡
                    edit_result = self.edit_paragraph(
                        source_text, 
                        user_trans, 
                        ai_trans,
                        alignment_info=alignment_info
                    )
                    result = {
                        **item,
                        "ai_translations": edit_result["ai_translations"],
                        "review": edit_result["review"],
                        "final": edit_result["final"],
                        "edited": True,
                        "has_user_translation": True
                    }
                else:
                    # æ— ç”¨æˆ·è¯‘æ–‡ï¼Œä»…ç¿»è¯‘æ•´åˆ
                    integrate_result = self.translate_and_integrate(source_text, ai_trans)
                    
                    # æ·»åŠ æ¼è¯‘æ ‡è®°
                    review = integrate_result["review"]
                    if coverage == "missing":
                        review = "âš ï¸ æ­¤æ®µä¸ºæ¼è¯‘ï¼ŒåŸæ–‡æ²¡æœ‰å¯¹åº”è¯‘æ–‡ã€‚\n" + review
                    
                    result = {
                        **item,
                        "ai_translations": integrate_result["ai_translations"],
                        "review": review,
                        "final": integrate_result["final"],
                        "edited": False,
                        "has_user_translation": False
                    }
            except Exception as e:
                # å‡ºé”™æ—¶ä½¿ç”¨ç¬¬ä¸€ä¸ª AI ç¿»è¯‘ä½œä¸ºå¤‡é€‰
                result = {
                    **item,
                    "ai_translations": {},
                    "review": f"[å¤„ç†å‡ºé”™: {str(e)}]",
                    "final": source_text,  # ä¿ç•™åŸæ–‡
                    "edited": False,
                    "has_user_translation": bool(user_trans),
                    "error": str(e)
                }
            
            with lock:
                processed += 1
                if progress_callback:
                    progress_callback(processed, len(aligned))
            
            return result
        
        # å¹¶å‘å¤„ç†
        print(f"\nğŸš€ å¼€å§‹å¤„ç† {len(aligned)} ä¸ªæ®µè½ (å¹¶å‘æ•°: {max_workers})...")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(process_paragraph, item): item for item in aligned}
            
            for future in as_completed(futures):
                try:
                    result = future.result()
                    processed_results.append(result)
                    if result.get("edited"):
                        results["stats"]["edited"] += 1
                    elif not result.get("has_user_translation"):
                        results["stats"]["translated_only"] += 1
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†æ®µè½å¤±è´¥: {e}")
        
        # æŒ‰é¡µç å’Œç´¢å¼•æ’åº
        processed_results.sort(key=lambda x: (x.get("page", 0), x.get("source_index", 0)))
        results["paragraphs"] = processed_results
        
        return results
    
    def generate_output_files(self, results: Dict, base_name: str) -> Dict[str, str]:
        """
        ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
        
        Returns:
            {"final": path, "review": path, "comparison": path}
        """
        output_files = {}
        model_suffix = self.editor_model.split("/")[-1].replace(".", "-")[:15]
        
        # 1. æœ€ç»ˆè¯‘æ–‡
        final_file = self.output_dir / f"{base_name}_edited_{model_suffix}.txt"
        with open(final_file, 'w', encoding='utf-8') as f:
            f.write("â”" + "â”" * 58 + "â”“\n")
            f.write("â”ƒ" + "  ç¼–è¾‘æ‰“ç£¨åçš„æœ€ç»ˆè¯‘æ–‡  ".center(50) + "â”ƒ\n")
            f.write("â”—" + "â”" * 58 + "â”›\n\n")
            
            current_page = None
            for para in results["paragraphs"]:
                page = para.get("page", 0)
                if page != current_page:
                    f.write(f"\nâ•”{'â•' * 20} ç¬¬ {page} é¡µ {'â•' * 20}â•—\n\n")
                    current_page = page
                
                f.write(para.get("final", "") + "\n\n")
        
        output_files["final"] = str(final_file)
        
        # 2. è¯„å®¡æŠ¥å‘Š
        review_file = self.output_dir / f"{base_name}_review_{model_suffix}.txt"
        with open(review_file, 'w', encoding='utf-8') as f:
            f.write("â”" + "â”" * 58 + "â”“\n")
            f.write("â”ƒ" + "  ç¼–è¾‘å®¡æ ¡æŠ¥å‘Š  ".center(50) + "â”ƒ\n")
            f.write("â”—" + "â”" * 58 + "â”›\n\n")
            
            stats = results["stats"]
            f.write(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:\n")
            f.write(f"  - æ€»æ®µè½æ•°: {stats['total']}\n")
            f.write(f"  - æˆåŠŸå¯¹é½: {stats['matched']}\n")
            f.write(f"  - å®Œæˆç¼–è¾‘: {stats['edited']}\n")
            f.write(f"  - ä»…AIç¿»è¯‘: {stats['translated_only']}\n")
            f.write(f"\nğŸ“‹ å¯¹é½è¯¦æƒ…:\n")
            f.write(f"  - è·³è¿‡æ®µè½: {stats.get('skipped', 0)} (å‡ºç‰ˆä¿¡æ¯ç­‰)\n")
            f.write(f"  - æ¼è¯‘æ®µè½: {stats.get('missing', 0)}\n")
            f.write(f"  - é‡å è¦†ç›–: {stats.get('overlap', 0)}\n")
            f.write(f"  - å¤šè¯‘æ–‡å¯¹åº”: {stats.get('multi_target', 0)}\n")
            f.write(f"\n{'â”€' * 60}\n\n")
            
            for i, para in enumerate(results["paragraphs"], 1):
                f.write(f"â•”{'â•' * 56}â•—\n")
                f.write(f"â•‘ æ®µè½ {i} | ç¬¬ {para.get('page', 0)} é¡µ | ")
                if para.get("edited"):
                    f.write("âœ… å·²ç¼–è¾‘å®¡æ ¡\n")
                elif para.get("has_user_translation"):
                    f.write("âš ï¸ æœ‰ç”¨æˆ·è¯‘æ–‡ä½†æœªç¼–è¾‘\n")
                else:
                    f.write("ğŸ“ æ— ç”¨æˆ·è¯‘æ–‡ï¼Œä½¿ç”¨AIç¿»è¯‘\n")
                f.write(f"â•š{'â•' * 56}â•\n\n")
                
                # æ˜¾ç¤ºå¯¹é½ä¿¡æ¯
                coverage = para.get("coverage", "")
                is_multi = para.get("is_multi_target", False)
                align_note = para.get("alignment_note", "")
                
                if coverage or is_multi or align_note:
                    f.write("ã€å¯¹é½ä¿¡æ¯ã€‘")
                    if coverage == "overlap":
                        f.write("ğŸ”€ é‡å è¦†ç›– ")
                    elif coverage == "missing":
                        f.write("âš ï¸ æ¼è¯‘ ")
                    elif coverage == "partial":
                        f.write("ğŸ“Œ éƒ¨åˆ†ç¿»è¯‘ ")
                    elif coverage == "skip":
                        f.write("â­ï¸ è·³è¿‡ ")
                    if is_multi:
                        f.write(f"| å¯¹åº” {len(para.get('target_indices', []))} ä¸ªè¯‘æ–‡æ®µè½ ")
                    if align_note:
                        f.write(f"| {align_note}")
                    f.write("\n\n")
                
                # åŸæ–‡æ‘˜è¦
                src_text = para.get("source_text", "")
                f.write(f"ã€åŸæ–‡æ‘˜è¦ã€‘\n{src_text[:200]}{'...' if len(src_text) > 200 else ''}\n\n")
                
                # ç”¨æˆ·è¯‘æ–‡ï¼ˆå¦‚æœ‰ï¼‰
                if para.get("target_text"):
                    user_text = para.get("target_text", "")
                    f.write(f"ã€ç”¨æˆ·è¯‘æ–‡ã€‘\n{user_text[:200]}{'...' if len(user_text) > 200 else ''}\n\n")
                
                # è¯„å®¡æ„è§
                f.write(f"ã€è¯„å®¡æ„è§ã€‘\n{para.get('review', 'æ— ')}\n\n")
                
                f.write(f"{'â”€' * 60}\n\n")
        
        output_files["review"] = str(review_file)
        
        # 3. å®Œæ•´å¯¹ç…§
        comparison_file = self.output_dir / f"{base_name}_comparison_{model_suffix}.txt"
        with open(comparison_file, 'w', encoding='utf-8') as f:
            f.write("â”" + "â”" * 58 + "â”“\n")
            f.write("â”ƒ" + "  å®Œæ•´ç¿»è¯‘å¯¹ç…§  ".center(50) + "â”ƒ\n")
            f.write("â”—" + "â”" * 58 + "â”›\n\n")
            
            for i, para in enumerate(results["paragraphs"], 1):
                f.write(f"â•”{'â•' * 56}â•—\n")
                f.write(f"â•‘ æ®µè½ {i} - ç¬¬ {para.get('page', 0)} é¡µ\n")
                f.write(f"â•š{'â•' * 56}â•\n\n")
                
                f.write("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n")
                f.write("â”‚ ã€åŸæ–‡ã€‘                                â”‚\n")
                f.write("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")
                f.write(para.get("source_text", "") + "\n\n")
                
                if para.get("target_text"):
                    f.write("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n")
                    f.write("â”‚ ã€ç”¨æˆ·è¯‘æ–‡ã€‘                            â”‚\n")
                    f.write("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")
                    f.write(para.get("target_text", "") + "\n\n")
                
                f.write("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n")
                f.write("â”‚ ã€AI å‚è€ƒè¯‘æ–‡ã€‘                         â”‚\n")
                f.write("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")
                for model, trans in para.get("ai_translations", {}).items():
                    model_display = model.split("_", 1)[-1] if "_" in model else model
                    model_short = model_display.split("/")[-1] if "/" in model_display else model_display
                    f.write(f"â—† {model_short}:\n{trans}\n\n")
                
                f.write("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n")
                f.write("â”‚ ã€è¯„å®¡æ„è§ã€‘                            â”‚\n")
                f.write("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")
                f.write(para.get("review", "") + "\n\n")
                
                f.write("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n")
                f.write("â”‚ ã€âœ¨ æœ€ç»ˆè¯‘æ–‡ã€‘                         â”‚\n")
                f.write("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")
                f.write(para.get("final", "") + "\n\n")
                
                f.write("â•" * 60 + "\n\n")
        
        output_files["comparison"] = str(comparison_file)
        
        print(f"\nâœ¨ è¾“å‡ºæ–‡ä»¶å·²ç”Ÿæˆ:")
        print(f"  ğŸ“„ æœ€ç»ˆè¯‘æ–‡: {final_file}")
        print(f"  ğŸ“‹ è¯„å®¡æŠ¥å‘Š: {review_file}")
        print(f"  ğŸ“š å®Œæ•´å¯¹ç…§: {comparison_file}")
        
        return output_files


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ç¼–è¾‘æœåŠ¡ - å¯¹æ¯”ã€è¯„å®¡ã€æ‰“ç£¨è¯‘æ–‡",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python editor_service.py original.pdf translation.docx
  python editor_service.py original.pdf translation.docx --start 1 --end 10
  python editor_service.py original.pdf translation.docx --editor-model anthropic/claude-sonnet-4
        """
    )
    
    parser.add_argument("pdf_path", help="PDF åŸæ–‡è·¯å¾„")
    parser.add_argument("word_path", help="Word è¯‘æ–‡è·¯å¾„")
    parser.add_argument("--start", type=int, help="èµ·å§‹é¡µç ")
    parser.add_argument("--end", type=int, help="ç»“æŸé¡µç ")
    parser.add_argument("--translation-models", help="ç¿»è¯‘æ¨¡å‹åˆ—è¡¨ï¼Œé€—å·åˆ†éš”")
    parser.add_argument("--editor-model", help="ç¼–è¾‘æ¨¡å‹")
    parser.add_argument("--workers", type=int, default=5, help="å¹¶å‘æ•° (é»˜è®¤: 5)")
    parser.add_argument("--output", default="output", help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ–‡ä»¶
    if not Path(args.pdf_path).exists():
        print(f"âŒ PDF æ–‡ä»¶ä¸å­˜åœ¨: {args.pdf_path}")
        return 1
    
    if not Path(args.word_path).exists():
        print(f"âŒ Word æ–‡ä»¶ä¸å­˜åœ¨: {args.word_path}")
        return 1
    
    # è§£ææ¨¡å‹åˆ—è¡¨
    translation_models = None
    if args.translation_models:
        translation_models = [m.strip() for m in args.translation_models.split(",")]
    
    # åˆ›å»ºç¼–è¾‘æœåŠ¡
    editor = EditorService(
        translation_models=translation_models,
        editor_model=args.editor_model,
        output_dir=args.output
    )
    
    # å¤„ç†æ–‡æ¡£
    def progress_callback(completed, total):
        print(f"\râ³ è¿›åº¦: {completed}/{total} ({completed/total*100:.1f}%)", end="", flush=True)
    
    results = editor.process_document(
        pdf_path=args.pdf_path,
        word_path=args.word_path,
        start_page=args.start,
        end_page=args.end,
        max_workers=args.workers,
        progress_callback=progress_callback
    )
    
    print()  # æ¢è¡Œ
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
    base_name = Path(args.pdf_path).stem
    editor.generate_output_files(results, base_name)
    
    return 0


if __name__ == "__main__":
    exit(main())
