#!/usr/bin/env python3
"""
PDFæ³•è¯­ç¿»è¯‘å·¥å…· - é€æ®µç¿»è¯‘å¤§å‹PDFæ–‡æ¡£
æ”¯æŒæ–­ç‚¹ç»­ä¼ ã€å¹¶å‘ç¿»è¯‘ï¼Œæ¯æ®µç‹¬ç«‹è°ƒç”¨APIç¡®ä¿ç¿»è¯‘è´¨é‡
"""

import os
import re
import json
import time
import argparse
import threading
from pathlib import Path
from typing import Generator
from collections import Counter
from concurrent.futures import ThreadPoolExecutor, as_completed

import fitz  # PyMuPDF
from openai import OpenAI
from dotenv import load_dotenv
from tqdm import tqdm

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# é»˜è®¤éœ€è¦è¿‡æ»¤çš„æ°´å°/è§’æ³¨æ¨¡å¼ï¼ˆé’ˆå¯¹è¿™æœ¬PDFï¼‰
DEFAULT_FILTER_PATTERNS = [
    r'^\d{2}/\d{2}/\d{4}\s+\d{2}:\d{2}:\d{2}$',  # æ—¶é—´æˆ³ å¦‚ 19/12/2023   10:20:10
    r'^Ã‰PREUVES$',
    r'^NON$',
    r'^CORRIGÃ‰ES$',
    r'^TOUS DROITS DE REPRODUCTION',  # ç‰ˆæƒå£°æ˜
    r'^\d+AFC.*\.indd\s+\d+$',  # æ–‡ä»¶å+é¡µç  å¦‚ 420601AFC_SECRET_CC2021_PC.indd   5
    r'^420601AFC.*\.indd\s+\d+$',  # å…·ä½“æ–‡ä»¶å
]


class PDFTranslator:
    """PDFç¿»è¯‘å™¨ç±»"""
    
    def __init__(
        self,
        api_key: str = None,
        base_url: str = None,
        model: str = "gpt-4o-mini",
        max_chars_per_segment: int = 2000,
        output_dir: str = "output",
        header_ratio: float = 0.08,
        footer_ratio: float = 0.92,
        filter_patterns: list = None,
        auto_detect_watermarks: bool = True
    ):
        """
        åˆå§‹åŒ–ç¿»è¯‘å™¨
        
        Args:
            api_key: OpenAI APIå¯†é’¥
            base_url: APIåŸºç¡€URLï¼ˆå¯é€‰ï¼Œç”¨äºå…¼å®¹å…¶ä»–APIï¼‰
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            max_chars_per_segment: æ¯æ®µæœ€å¤§å­—ç¬¦æ•°
            output_dir: è¾“å‡ºç›®å½•
            header_ratio: é¡µçœ‰åŒºåŸŸæ¯”ä¾‹ï¼ˆé¡µé¢é¡¶éƒ¨å¤šå°‘æ¯”ä¾‹è§†ä¸ºé¡µçœ‰ï¼‰
            footer_ratio: é¡µè„šåŒºåŸŸæ¯”ä¾‹ï¼ˆé¡µé¢åº•éƒ¨ä»å“ªé‡Œå¼€å§‹è§†ä¸ºé¡µè„šï¼‰
            filter_patterns: è‡ªå®šä¹‰è¿‡æ»¤æ­£åˆ™è¡¨è¾¾å¼åˆ—è¡¨
            auto_detect_watermarks: æ˜¯å¦è‡ªåŠ¨æ£€æµ‹æ°´å°
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.base_url = base_url or os.getenv("OPENAI_BASE_URL")
        self.model = model or os.getenv("MODEL_NAME", "gpt-4o-mini")
        self.max_chars = max_chars_per_segment
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # é¡µçœ‰é¡µè„šåŒºåŸŸè®¾ç½®
        self.header_ratio = header_ratio
        self.footer_ratio = footer_ratio
        
        # è¿‡æ»¤æ¨¡å¼
        self.filter_patterns = filter_patterns or DEFAULT_FILTER_PATTERNS
        self.auto_detect_watermarks = auto_detect_watermarks
        self.detected_watermarks = set()  # è‡ªåŠ¨æ£€æµ‹åˆ°çš„æ°´å°
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        client_kwargs = {"api_key": self.api_key}
        if self.base_url:
            client_kwargs["base_url"] = self.base_url
        self.client = OpenAI(**client_kwargs)
        
        # ç¿»è¯‘æç¤ºè¯ - æ¯æ¬¡è°ƒç”¨éƒ½ä¼šä½¿ç”¨
        self.system_prompt = """ä½ æ˜¯ä¸€ä½ç²¾é€šæ³•è¯­å’Œä¸­æ–‡çš„ä¸“ä¸šç¿»è¯‘å®˜ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å°†è¾“å…¥çš„æ³•è¯­æ–‡æœ¬ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚
è¦æ±‚ï¼š
1. ä¿æŒç¿»è¯‘çš„å­¦æœ¯æ€§æˆ–æ–‡å­¦æ€§ï¼Œè¯­æ°”çµåŠ¨è‡ªç„¶ä¼˜é›…ï¼Œè¡¨è¾¾é¡ºç•…å‡†ç¡®ï¼Œç¡®ä¿è¯­å¥ç»“æ„å®Œæ•´ï¼Œä¼˜å…ˆä½¿ç”¨ç®€æ´å¥å¼ï¼Œä¿è¯è¡Œæ–‡æ˜“æ‡‚ï¼Œä¿è¯æ‰€æœ‰å“²å­¦å­¦æœ¯æœ¯è¯­çš„å‡†ç¡®æ€§ï¼Œåœ¨ä½ è§‰å¾—é‡è¦çš„å“²å­¦å­¦æœ¯æœ¯è¯­åé¢åŠ æ‹¬å·ï¼Œåœ¨æ‹¬å·å†…æ ‡æ³¨åŸæ–‡å¹¶è¿›è¡Œä¸€åˆ°ä¸¤å¥è¯çš„è§£é‡Šç”¨äºè¯¥æ–‡æœ¬çš„è„šæ³¨ã€‚
2. ä¿ç•™åŸæœ‰çš„æ ¼å¼ï¼ˆå¦‚æ ‡é¢˜ã€åˆ—è¡¨ï¼‰ã€‚
3. ç›´æ¥è¿”å›ç¿»è¯‘åçš„ä¸­æ–‡å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–è¯´æ˜ã€‚
"""

    def _should_filter_line(self, line: str) -> bool:
        """
        æ£€æŸ¥ä¸€è¡Œæ–‡æœ¬æ˜¯å¦åº”è¯¥è¢«è¿‡æ»¤
        
        Args:
            line: æ–‡æœ¬è¡Œ
            
        Returns:
            æ˜¯å¦åº”è¯¥è¿‡æ»¤
        """
        line = line.strip()
        if not line:
            return True
            
        # æ£€æŸ¥è‡ªåŠ¨æ£€æµ‹åˆ°çš„æ°´å°
        if line in self.detected_watermarks:
            return True
            
        # æ£€æŸ¥æ­£åˆ™æ¨¡å¼
        for pattern in self.filter_patterns:
            if re.match(pattern, line, re.IGNORECASE):
                return True
        
        return False

    def _detect_watermarks(self, pdf_path: str, sample_pages: int = 30) -> set:
        """
        è‡ªåŠ¨æ£€æµ‹PDFä¸­çš„æ°´å°ï¼ˆåœ¨å¤šé¡µé‡å¤å‡ºç°çš„å†…å®¹ï¼‰
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            sample_pages: é‡‡æ ·é¡µæ•°
            
        Returns:
            æ£€æµ‹åˆ°çš„æ°´å°æ–‡æœ¬é›†åˆ
        """
        doc = fitz.open(pdf_path)
        total_pages = len(doc)
        pages_to_check = min(sample_pages, total_pages)
        
        # æ”¶é›†æ‰€æœ‰æ–‡æœ¬è¡Œ
        all_lines = []
        for page_num in range(pages_to_check):
            page = doc[page_num]
            text = page.get_text("text")
            lines = [line.strip() for line in text.split('\n') if line.strip()]
            all_lines.extend(lines)
        
        doc.close()
        
        # ç»Ÿè®¡æ¯è¡Œå‡ºç°çš„æ¬¡æ•°
        line_counter = Counter(all_lines)
        
        # å‡ºç°åœ¨60%ä»¥ä¸Šé¡µé¢çš„çŸ­æ–‡æœ¬ï¼ˆ<100å­—ç¬¦ï¼‰è§†ä¸ºæ°´å°
        threshold = pages_to_check * 0.6
        watermarks = set()
        
        for line, count in line_counter.items():
            if count >= threshold and len(line) < 100:
                watermarks.add(line)
        
        return watermarks

    def extract_text_from_pdf(self, pdf_path: str) -> list[dict]:
        """
        ä»PDFæå–æ–‡æœ¬ï¼ŒæŒ‰é¡µåˆ†å‰²ï¼Œè‡ªåŠ¨è¿‡æ»¤æ°´å°å’Œé¡µçœ‰é¡µè„š
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«é¡µç å’Œæ–‡æœ¬çš„å­—å…¸åˆ—è¡¨
        """
        # è‡ªåŠ¨æ£€æµ‹æ°´å°
        if self.auto_detect_watermarks:
            print("ğŸ” æ­£åœ¨è‡ªåŠ¨æ£€æµ‹æ°´å°...")
            self.detected_watermarks = self._detect_watermarks(pdf_path)
            if self.detected_watermarks:
                print(f"âœ… æ£€æµ‹åˆ° {len(self.detected_watermarks)} ä¸ªæ°´å°/é‡å¤å†…å®¹ï¼Œå°†è‡ªåŠ¨è¿‡æ»¤")
                for wm in list(self.detected_watermarks)[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"   - {wm[:50]}{'...' if len(wm) > 50 else ''}")
                if len(self.detected_watermarks) > 5:
                    print(f"   ... ç­‰ {len(self.detected_watermarks)} é¡¹")
        
        doc = fitz.open(pdf_path)
        pages_text = []
        filtered_count = 0
        
        for page_num in range(len(doc)):
            page = doc[page_num]
            rect = page.rect
            
            # è®¡ç®—é¡µçœ‰é¡µè„šè¾¹ç•Œ
            header_threshold = rect.height * self.header_ratio
            footer_threshold = rect.height * self.footer_ratio
            
            # ä½¿ç”¨å—çº§æå–è·å–ä½ç½®ä¿¡æ¯
            blocks = page.get_text("blocks")
            
            page_lines = []
            for block in blocks:
                if block[6] == 0:  # æ–‡æœ¬å— (type 0)
                    x0, y0, x1, y1, text, block_no, block_type = block
                    text = text.strip()
                    
                    if not text:
                        continue
                    
                    # è¿‡æ»¤é¡µçœ‰åŒºåŸŸ
                    if y0 < header_threshold:
                        filtered_count += 1
                        continue
                    
                    # è¿‡æ»¤é¡µè„šåŒºåŸŸ
                    if y1 > footer_threshold:
                        filtered_count += 1
                        continue
                    
                    # æŒ‰è¡Œå¤„ç†æ–‡æœ¬å—ï¼Œè¿‡æ»¤æ°´å°
                    lines = text.split('\n')
                    clean_lines = []
                    for line in lines:
                        if not self._should_filter_line(line):
                            clean_lines.append(line.strip())
                        else:
                            filtered_count += 1
                    
                    if clean_lines:
                        page_lines.append('\n'.join(clean_lines))
            
            # åˆå¹¶é¡µé¢æ–‡æœ¬
            page_text = '\n\n'.join(page_lines)
            
            if page_text.strip():
                pages_text.append({
                    "page": page_num + 1,
                    "text": page_text.strip()
                })
        
        doc.close()
        print(f"ğŸ—‘ï¸  å·²è¿‡æ»¤ {filtered_count} ä¸ªæ°´å°/é¡µçœ‰é¡µè„šå†…å®¹")
        return pages_text

    def split_into_segments(self, pages_text: list[dict]) -> list[dict]:
        """
        å°†é¡µé¢æ–‡æœ¬åˆ†å‰²æˆé€‚åˆç¿»è¯‘çš„æ®µè½
        
        Args:
            pages_text: é¡µé¢æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            åˆ†æ®µåçš„æ–‡æœ¬åˆ—è¡¨
        """
        segments = []
        segment_id = 0
        
        for page_data in pages_text:
            page_num = page_data["page"]
            text = page_data["text"]
            
            # æŒ‰æ®µè½åˆ†å‰²
            paragraphs = text.split('\n\n')
            current_segment = ""
            
            for para in paragraphs:
                para = para.strip()
                if not para:
                    continue
                    
                # å¦‚æœå½“å‰æ®µè½åŠ ä¸Šæ–°æ®µè½ä¸è¶…è¿‡é™åˆ¶ï¼Œåˆå¹¶
                if len(current_segment) + len(para) + 2 <= self.max_chars:
                    if current_segment:
                        current_segment += "\n\n" + para
                    else:
                        current_segment = para
                else:
                    # ä¿å­˜å½“å‰æ®µè½ï¼Œå¼€å§‹æ–°æ®µè½
                    if current_segment:
                        segments.append({
                            "id": segment_id,
                            "page": page_num,
                            "text": current_segment
                        })
                        segment_id += 1
                    
                    # å¦‚æœå•ä¸ªæ®µè½å°±è¶…è¿‡é™åˆ¶ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†å‰²
                    if len(para) > self.max_chars:
                        # æŒ‰å¥å­åˆ†å‰²
                        sentences = para.replace('ã€‚', 'ã€‚\n').replace('. ', '.\n').split('\n')
                        current_segment = ""
                        for sent in sentences:
                            sent = sent.strip()
                            if not sent:
                                continue
                            if len(current_segment) + len(sent) + 1 <= self.max_chars:
                                current_segment = current_segment + " " + sent if current_segment else sent
                            else:
                                if current_segment:
                                    segments.append({
                                        "id": segment_id,
                                        "page": page_num,
                                        "text": current_segment
                                    })
                                    segment_id += 1
                                current_segment = sent
                    else:
                        current_segment = para
            
            # ä¿å­˜æœ€åä¸€ä¸ªæ®µè½
            if current_segment:
                segments.append({
                    "id": segment_id,
                    "page": page_num,
                    "text": current_segment
                })
                segment_id += 1
        
        return segments

    def translate_segment(self, text: str, retry_count: int = 3) -> str:
        """
        ç¿»è¯‘å•ä¸ªæ®µè½ï¼Œæ”¯æŒç©ºè¿”å›æ£€æµ‹å’Œè‡ªåŠ¨é‡è¯•
        
        Args:
            text: è¦ç¿»è¯‘çš„æ–‡æœ¬
            retry_count: é‡è¯•æ¬¡æ•°
            
        Returns:
            ç¿»è¯‘åçš„æ–‡æœ¬
        """
        for attempt in range(retry_count):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": self.system_prompt},
                        {"role": "user", "content": f"è¯·å°†ä»¥ä¸‹æ³•è¯­æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ï¼š\n\n{text}"}
                    ],
                    temperature=0.3,  # è¾ƒä½çš„æ¸©åº¦ç¡®ä¿ç¿»è¯‘ä¸€è‡´æ€§
                    max_tokens=4000
                )
                result = response.choices[0].message.content
                
                # æ£€æµ‹ç©ºè¿”å›æˆ–æ— æ•ˆè¿”å›
                if not result or not result.strip():
                    print(f"\nâš ï¸  è¿”å›ä¸ºç©º (å°è¯• {attempt + 1}/{retry_count})ï¼Œæ­£åœ¨é‡è¯•...")
                    if attempt < retry_count - 1:
                        time.sleep(2 ** attempt)
                        continue
                    else:
                        return f"[ç¿»è¯‘è¿”å›ä¸ºç©ºï¼ŒåŸæ–‡ä¿ç•™]\n{text}"
                
                return result.strip()
                
            except Exception as e:
                print(f"\nâŒ ç¿»è¯‘å‡ºé”™ (å°è¯• {attempt + 1}/{retry_count}): {e}")
                if attempt < retry_count - 1:
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                else:
                    return f"[ç¿»è¯‘å¤±è´¥: {str(e)}]\nåŸæ–‡: {text}"
        
        return f"[ç¿»è¯‘å¤±è´¥]\nåŸæ–‡: {text}"

    def load_progress(self, progress_file: Path) -> dict:
        """åŠ è½½è¿›åº¦æ–‡ä»¶ï¼Œå¤„ç†ç©ºæ–‡ä»¶æˆ–æŸåçš„æƒ…å†µ"""
        if progress_file.exists():
            try:
                with open(progress_file, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    if content:
                        return json.loads(content)
            except (json.JSONDecodeError, Exception) as e:
                print(f"âš ï¸  è¿›åº¦æ–‡ä»¶æŸåï¼Œå°†é‡æ–°å¼€å§‹: {e}")
        return {"completed": [], "translations": {}}

    def save_progress(self, progress_file: Path, progress: dict):
        """ä¿å­˜è¿›åº¦æ–‡ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰ï¼Œcompletedåˆ—è¡¨ä¿æŒæ’åº"""
        # å¯¹completedåˆ—è¡¨æ’åºï¼Œæ–¹ä¾¿æŸ¥çœ‹
        progress_to_save = {
            "completed": sorted(progress["completed"]),
            "translations": progress["translations"]
        }
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_to_save, f, ensure_ascii=False, indent=2)

    def _translate_single(self, segment: dict, progress: dict, progress_file: Path, 
                          translations: dict, lock: threading.Lock, pbar: tqdm) -> dict:
        """
        ç¿»è¯‘å•ä¸ªæ®µè½ï¼ˆç”¨äºå¹¶å‘ï¼‰
        """
        seg_id = segment["id"]
        
        try:
            translated = self.translate_segment(segment["text"])
            
            # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°è¿›åº¦
            with lock:
                translations[str(seg_id)] = {
                    "page": segment["page"],
                    "original": segment["text"],
                    "translated": translated
                }
                
                if seg_id not in progress["completed"]:
                    progress["completed"].append(seg_id)
                
                # ä¿å­˜è¿›åº¦
                self.save_progress(progress_file, progress)
                pbar.update(1)
            
            return {"id": seg_id, "success": True, "translated": translated}
        except Exception as e:
            return {"id": seg_id, "success": False, "error": str(e)}

    def translate_pdf(
        self,
        pdf_path: str,
        start_page: int = None,
        end_page: int = None,
        delay_between_calls: float = 0.5,
        max_workers: int = 5
    ) -> str:
        """
        ç¿»è¯‘æ•´ä¸ªPDFï¼ˆæ”¯æŒå¹¶å‘ï¼‰
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            start_page: èµ·å§‹é¡µç ï¼ˆå¯é€‰ï¼‰
            end_page: ç»“æŸé¡µç ï¼ˆå¯é€‰ï¼‰
            delay_between_calls: APIè°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰- å¹¶å‘æ¨¡å¼ä¸‹å¿½ç•¥
            max_workers: å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤5ï¼‰
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        pdf_path = Path(pdf_path)
        pdf_name = pdf_path.stem
        
        # æ¨¡å‹åå¤„ç†ï¼šå»æ‰æ–œæ ç­‰ç‰¹æ®Šå­—ç¬¦ï¼Œç”¨äºæ–‡ä»¶å
        model_suffix = self.model.replace("/", "_").replace(":", "_") if self.model else "unknown"
        
        # è¿›åº¦æ–‡ä»¶ï¼ˆåŒ…å«æ¨¡å‹åï¼Œä¸åŒæ¨¡å‹è¿›åº¦ç‹¬ç«‹ï¼‰
        progress_file = self.output_dir / f"{pdf_name}_progress_{model_suffix}.json"
        
        print(f"ğŸ“– æ­£åœ¨è¯»å–PDF: {pdf_path}")
        
        # æå–æ–‡æœ¬
        pages_text = self.extract_text_from_pdf(str(pdf_path))
        print(f"âœ… æˆåŠŸæå– {len(pages_text)} é¡µæ–‡æœ¬")
        
        # ç­›é€‰é¡µé¢èŒƒå›´
        if start_page or end_page:
            pages_text = [
                p for p in pages_text 
                if (start_page is None or p["page"] >= start_page) and
                   (end_page is None or p["page"] <= end_page)
            ]
            print(f"ğŸ“„ é€‰æ‹©é¡µé¢èŒƒå›´: {start_page or 1} - {end_page or 'æœ«é¡µ'}")
        
        # åˆ†æ®µ
        segments = self.split_into_segments(pages_text)
        print(f"ğŸ“ å…±åˆ†å‰²æˆ {len(segments)} ä¸ªç¿»è¯‘æ®µè½")
        
        # åŠ è½½è¿›åº¦
        progress = self.load_progress(progress_file)
        completed_ids = set(progress["completed"])
        translations = progress["translations"]
        
        if completed_ids:
            print(f"ğŸ“Œ å‘ç°å·²æœ‰è¿›åº¦ï¼Œå·²å®Œæˆ {len(completed_ids)}/{len(segments)} æ®µ")
        
        # ç­›é€‰éœ€è¦ç¿»è¯‘çš„æ®µè½ï¼ˆè·³è¿‡å·²å®Œæˆä¸”æœ‰æ•ˆçš„ï¼‰
        segments_to_translate = []
        for segment in segments:
            seg_id = segment["id"]
            existing = translations.get(str(seg_id), {})
            existing_trans = existing.get("translated", "")
            
            if str(seg_id) in completed_ids or seg_id in completed_ids:
                if existing_trans and existing_trans.strip():
                    continue  # å·²æœ‰æœ‰æ•ˆç¿»è¯‘ï¼Œè·³è¿‡
                else:
                    print(f"ğŸ”„ æ®µè½ {seg_id} ç¿»è¯‘ä¸ºç©ºï¼Œå°†é‡æ–°ç¿»è¯‘")
            
            segments_to_translate.append(segment)
        
        if not segments_to_translate:
            print("âœ… æ‰€æœ‰æ®µè½å·²ç¿»è¯‘å®Œæˆï¼")
        else:
            # å¼€å§‹å¹¶å‘ç¿»è¯‘
            print(f"\nğŸš€ å¼€å§‹å¹¶å‘ç¿»è¯‘... (æ¨¡å‹: {self.model}, å¹¶å‘æ•°: {max_workers})")
            print("=" * 50)
            
            lock = threading.Lock()
            
            try:
                with tqdm(total=len(segments_to_translate), desc="ç¿»è¯‘è¿›åº¦") as pbar:
                    with ThreadPoolExecutor(max_workers=max_workers) as executor:
                        futures = {
                            executor.submit(
                                self._translate_single, 
                                segment, progress, progress_file, 
                                translations, lock, pbar
                            ): segment 
                            for segment in segments_to_translate
                        }
                        
                        for future in as_completed(futures):
                            result = future.result()
                            if not result["success"]:
                                print(f"\nâš ï¸  æ®µè½ {result['id']} ç¿»è¯‘å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                            
            except KeyboardInterrupt:
                print("\n\nâ¸ï¸  ç¿»è¯‘å·²æš‚åœï¼Œè¿›åº¦å·²ä¿å­˜ã€‚ä¸‹æ¬¡è¿è¡Œå°†ä»æ–­ç‚¹ç»§ç»­ã€‚")
                return None
        
        # ç”Ÿæˆæœ€ç»ˆæ–‡æ¡£
        print("\nğŸ“„ æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæ–‡æ¡£...")
        # æ¨¡å‹åå¤„ç†ï¼šå»æ‰æ–œæ ç­‰ç‰¹æ®Šå­—ç¬¦ï¼Œç”¨äºæ–‡ä»¶å
        model_suffix = self.model.replace("/", "_").replace(":", "_") if self.model else "unknown"
        output_file = self.output_dir / f"{pdf_name}_translated_{model_suffix}.txt"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            # ç¾è§‚çš„æ ‡é¢˜
            f.write("â”" + "â”" * 58 + "â”“\n")
            f.write("â”ƒ" + f" {pdf_name} ".center(58) + "â”ƒ\n")
            f.write("â”ƒ" + " ä¸­æ–‡ç¿»è¯‘ ".center(58) + "â”ƒ\n")
            f.write("â”£" + "â”" * 58 + "â”«\n")
            f.write("â”ƒ" + f" åŸæ–‡è¯­è¨€: æ³•è¯­ | ç¿»è¯‘æ¨¡å‹: {self.model} ".center(58) + "â”ƒ\n")
            f.write("â”—" + "â”" * 58 + "â”›\n\n")
            
            current_page = None
            for i in range(len(segments)):
                trans_data = translations.get(str(i), {})
                page = trans_data.get("page", segments[i]["page"])
                translated = trans_data.get("translated", "[æœªç¿»è¯‘]")
                
                # ç¾è§‚çš„é¡µç æ ‡è®°
                if page != current_page:
                    f.write("\n")
                    f.write("â•”" + "â•" * 20 + f" ç¬¬ {page} é¡µ " + "â•" * 20 + "â•—\n")
                    f.write("\n")
                    current_page = page
                
                f.write(translated + "\n\n")
        
        # åŒæ—¶ç”ŸæˆåŒè¯­å¯¹ç…§ç‰ˆæœ¬
        bilingual_file = self.output_dir / f"{pdf_name}_bilingual_{model_suffix}.txt"
        with open(bilingual_file, 'w', encoding='utf-8') as f:
            # ç¾è§‚çš„æ ‡é¢˜
            f.write("â”" + "â”" * 58 + "â”“\n")
            f.write("â”ƒ" + f" {pdf_name} ".center(58) + "â”ƒ\n")
            f.write("â”ƒ" + " æ³•ä¸­åŒè¯­å¯¹ç…§ ".center(58) + "â”ƒ\n")
            f.write("â”—" + "â”" * 58 + "â”›\n\n")
            
            current_page = None
            for i in range(len(segments)):
                trans_data = translations.get(str(i), {})
                page = trans_data.get("page", segments[i]["page"])
                original = trans_data.get("original", segments[i]["text"])
                translated = trans_data.get("translated", "[æœªç¿»è¯‘]")
                
                if page != current_page:
                    f.write("\n")
                    f.write("â•”" + "â•" * 20 + f" ç¬¬ {page} é¡µ " + "â•" * 20 + "â•—\n")
                    f.write("\n")
                    current_page = page
                
                f.write("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n")
                f.write("â”‚ ã€åŸæ–‡ã€‘                                â”‚\n")
                f.write("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")
                f.write(original + "\n\n")
                f.write("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n")
                f.write("â”‚ ã€è¯‘æ–‡ã€‘                                â”‚\n")
                f.write("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")
                f.write(translated + "\n")
                f.write("â”€" * 45 + "\n\n")
        
        print(f"\nâœ¨ ç¿»è¯‘å®Œæˆ!")
        print(f"ğŸ“ è¯‘æ–‡æ–‡ä»¶: {output_file}")
        print(f"ğŸ“ åŒè¯­å¯¹ç…§: {bilingual_file}")
        
        return str(output_file)


def main():
    parser = argparse.ArgumentParser(
        description="PDFæ³•è¯­ç¿»è¯‘å·¥å…· - æ”¯æŒå¹¶å‘ç¿»è¯‘å¤§å‹PDFæ–‡æ¡£",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ç¿»è¯‘æ•´æœ¬ä¹¦ï¼ˆé»˜è®¤5å¹¶å‘ï¼‰
  python pdf_translator.py book.pdf
  
  # ç¿»è¯‘æŒ‡å®šé¡µé¢èŒƒå›´
  python pdf_translator.py book.pdf --start 1 --end 50
  
  # ä½¿ç”¨10ä¸ªå¹¶å‘åŠ é€Ÿç¿»è¯‘
  python pdf_translator.py book.pdf --workers 10
  
  # ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹
  python pdf_translator.py book.pdf --model gpt-4o

ä½¿ç”¨ OpenRouter API:
  python pdf_translator.py book.pdf \\
    --base-url https://openrouter.ai/api/v1 \\
    --api-key your_openrouter_key \\
    --model anthropic/claude-3.5-sonnet

OpenRouter æ¨èæ¨¡å‹:
  deepseek/deepseek-chat        # æœ€ä¾¿å®œ
  anthropic/claude-3.5-haiku    # å¿«é€Ÿ
  anthropic/claude-3.5-sonnet   # è´¨é‡æœ€å¥½

ç¯å¢ƒå˜é‡è®¾ç½® (.env æ–‡ä»¶):
  OPENAI_API_KEY=your_api_key
  OPENAI_BASE_URL=https://openrouter.ai/api/v1
  MODEL_NAME=deepseek/deepseek-chat
        """
    )
    
    parser.add_argument("pdf_path", help="PDFæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--start", type=int, help="èµ·å§‹é¡µç ")
    parser.add_argument("--end", type=int, help="ç»“æŸé¡µç ")
    parser.add_argument("--model", default=None, help="ä½¿ç”¨çš„æ¨¡å‹ (é»˜è®¤: gpt-4o-mini)")
    parser.add_argument("--max-chars", type=int, default=2000, help="æ¯æ®µæœ€å¤§å­—ç¬¦æ•° (é»˜è®¤: 2000)")
    parser.add_argument("--workers", type=int, default=5, help="å¹¶å‘çº¿ç¨‹æ•° (é»˜è®¤: 5)")
    parser.add_argument("--output", default="output", help="è¾“å‡ºç›®å½• (é»˜è®¤: output)")
    parser.add_argument("--api-key", help="APIå¯†é’¥ (ä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®)")
    parser.add_argument("--base-url", help="APIåŸºç¡€URL (ç”¨äºOpenRouterç­‰)")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥PDFæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(args.pdf_path).exists():
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {args.pdf_path}")
        return 1
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = args.api_key or os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: æœªè®¾ç½®APIå¯†é’¥")
        print("è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€è®¾ç½®:")
        print("  1. åˆ›å»º .env æ–‡ä»¶å¹¶æ·»åŠ : OPENAI_API_KEY=your_key")
        print("  2. ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°: --api-key your_key")
        print("  3. è®¾ç½®ç¯å¢ƒå˜é‡: export OPENAI_API_KEY=your_key")
        return 1
    
    # åˆ›å»ºç¿»è¯‘å™¨å¹¶å¼€å§‹ç¿»è¯‘
    translator = PDFTranslator(
        api_key=api_key,
        base_url=args.base_url,
        model=args.model,
        max_chars_per_segment=args.max_chars,
        output_dir=args.output
    )
    
    translator.translate_pdf(
        pdf_path=args.pdf_path,
        start_page=args.start,
        end_page=args.end,
        max_workers=args.workers
    )
    
    return 0


if __name__ == "__main__":
    exit(main())
