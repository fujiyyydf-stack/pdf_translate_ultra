# ç¼–è¾‘åŠŸèƒ½ï¼ˆEditor Modeï¼‰å¼€å‘æ–‡æ¡£

## 1. åŠŸèƒ½æ¦‚è¿°

### 1.1 éœ€æ±‚æè¿°

ç”¨æˆ·å·²æœ‰ä¸€ä»½è‡ªå·±ç¿»è¯‘çš„ Word æ–‡æ¡£ï¼Œå¸Œæœ›ç³»ç»Ÿèƒ½å¤Ÿï¼š
1. è¯»å–ç”¨æˆ·çš„ Word è¯‘æ–‡
2. ä¸ PDF åŸæ–‡è¿›è¡Œæ®µè½çº§å¯¹é½åŒ¹é…
3. è°ƒç”¨å¤šä¸ªå¤§æ¨¡å‹ï¼Œä¸€è¾¹ç‹¬ç«‹ç¿»è¯‘ï¼Œä¸€è¾¹å¯¹æ¯”ç”¨æˆ·è¯‘æ–‡
4. ä½œä¸º"ä¸¥å‰çš„ç¼–è¾‘"è§’è‰²ï¼Œè¯„å®¡å¹¶æ‰“ç£¨ç”¨æˆ·çš„è¯‘æ–‡
5. è¾“å‡ºä¸€ä¸ªè¶…è¶ŠåŸæœ‰è¯‘æ–‡çš„æœ€ç»ˆç‰ˆæœ¬

### 1.2 æ ¸å¿ƒä»·å€¼

- **è¯‘è€…è§†è§’**ï¼šç³»ç»Ÿç‹¬ç«‹ç¿»è¯‘ï¼Œæä¾›å‚è€ƒè¯‘æ–‡
- **ç¼–è¾‘è§†è§’**ï¼šè¯„å®¡ç”¨æˆ·è¯‘æ–‡ï¼ŒæŒ‡å‡ºé—®é¢˜å¹¶æå‡ºä¿®æ”¹å»ºè®®
- **æ•´åˆè§†è§’**ï¼šç»¼åˆå„æ–¹ä¼˜ç‚¹ï¼Œè¾“å‡ºæœ€ä¼˜ç‰ˆæœ¬

### 1.3 ä¸ç°æœ‰åŠŸèƒ½çš„å…³ç³»

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         PDF ç¿»è¯‘å·¥å…·                â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                       â”‚                       â”‚
            â–¼                       â–¼                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Flash Mode   â”‚      â”‚ High Quality  â”‚      â”‚  Editor Mode  â”‚
    â”‚   å•æ¨¡å‹ç¿»è¯‘   â”‚      â”‚  å¤šæ¨¡å‹ç¿»è¯‘    â”‚      â”‚  ç¼–è¾‘æ‰“ç£¨æ¨¡å¼  â”‚ â† æ–°åŠŸèƒ½
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. ç³»ç»Ÿæ¶æ„è®¾è®¡

### 2.1 æ¨¡å—ç»“æ„

```
pdf_translate/
â”œâ”€â”€ server.py                    # Flask æœåŠ¡ï¼ˆæ–°å¢ç¼–è¾‘ç›¸å…³è·¯ç”±ï¼‰
â”œâ”€â”€ editor_service.py            # ã€æ–°å¢ã€‘ç¼–è¾‘æœåŠ¡æ ¸å¿ƒæ¨¡å—
â”œâ”€â”€ word_processor.py            # ã€æ–°å¢ã€‘Word æ–‡æ¡£å¤„ç†æ¨¡å—
â”œâ”€â”€ text_aligner.py              # ã€æ–°å¢ã€‘æ–‡æœ¬å¯¹é½åŒ¹é…æ¨¡å—
â”œâ”€â”€ multi_model_translator.py    # ç°æœ‰å¤šæ¨¡å‹ç¿»è¯‘å™¨ï¼ˆå¤ç”¨ï¼‰
â”œâ”€â”€ pdf_translator.py            # ç°æœ‰PDFå¤„ç†å™¨ï¼ˆå¤ç”¨ï¼‰
â””â”€â”€ web/
    â”œâ”€â”€ index.html               # å‰ç«¯ä¸»é¡µï¼ˆæ–°å¢ç¼–è¾‘æ¨¡å¼tabï¼‰
    â”œâ”€â”€ editor.html              # ã€æ–°å¢ã€‘ç¼–è¾‘æ¨¡å¼é¡µé¢
    â”œâ”€â”€ style.css                # æ ·å¼ï¼ˆæ–°å¢ç¼–è¾‘ç›¸å…³æ ·å¼ï¼‰
    â””â”€â”€ app.js                   # å‰ç«¯é€»è¾‘ï¼ˆæ–°å¢ç¼–è¾‘åŠŸèƒ½ï¼‰
```

### 2.2 æ•°æ®æµç¨‹å›¾

```
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   ç”¨æˆ·ä¸Šä¼ æ–‡ä»¶    â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚                                 â”‚
                      â–¼                                 â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   PDF åŸæ–‡    â”‚                 â”‚  Word è¯‘æ–‡   â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                                â”‚
                     â–¼                                â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  æ–‡æœ¬æå–     â”‚                 â”‚  æ–‡æœ¬æå–     â”‚
              â”‚ (æŒ‰é¡µ/æ®µè½)   â”‚                 â”‚ (æŒ‰æ®µè½)      â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                                â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   æ®µè½å¯¹é½    â”‚
                         â”‚ Text Aligner â”‚
                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚        å¯¹é½åçš„æ®µè½å¯¹               â”‚
              â”‚  [(åŸæ–‡1, è¯‘æ–‡1), (åŸæ–‡2, è¯‘æ–‡2)..] â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                               â”‚
        â”‚              å¹¶å‘å¤„ç†æ¯ä¸ªæ®µè½                  â”‚
        â”‚                                               â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
        â”‚  â”‚ Model A â”‚  â”‚ Model B â”‚  â”‚ Model C â”‚       â”‚
        â”‚  â”‚ ç¿»è¯‘ç‰ˆæœ¬ â”‚  â”‚ ç¿»è¯‘ç‰ˆæœ¬ â”‚  â”‚ ç¿»è¯‘ç‰ˆæœ¬ â”‚       â”‚
        â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â”‚
        â”‚       â”‚            â”‚            â”‚            â”‚
        â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
        â”‚                    â”‚                         â”‚
        â”‚                    â–¼                         â”‚
        â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
        â”‚           â”‚   ç¼–è¾‘æ•´åˆæ¨¡å‹  â”‚                 â”‚
        â”‚           â”‚                â”‚                 â”‚
        â”‚           â”‚ è¾“å…¥ï¼š          â”‚                 â”‚
        â”‚           â”‚ - åŸæ–‡          â”‚                 â”‚
        â”‚           â”‚ - ç”¨æˆ·è¯‘æ–‡      â”‚                 â”‚
        â”‚           â”‚ - å¤šä¸ªAIè¯‘æ–‡    â”‚                 â”‚
        â”‚           â”‚                â”‚                 â”‚
        â”‚           â”‚ è¾“å‡ºï¼š          â”‚                 â”‚
        â”‚           â”‚ - è¯„å®¡åˆ†æ      â”‚                 â”‚
        â”‚           â”‚ - æœ€ç»ˆè¯‘æ–‡      â”‚                 â”‚
        â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
        â”‚                    â”‚                         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    è¾“å‡ºç»“æœ       â”‚
                    â”‚ - æœ€ç»ˆæ‰“ç£¨è¯‘æ–‡    â”‚
                    â”‚ - è¯„å®¡æŠ¥å‘Š        â”‚
                    â”‚ - ä¿®æ”¹è¿½è¸ª        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. æ ¸å¿ƒæ¨¡å—è®¾è®¡

### 3.1 Word æ–‡æ¡£å¤„ç†æ¨¡å— (`word_processor.py`)

```python
"""
Word æ–‡æ¡£å¤„ç†æ¨¡å—
åŠŸèƒ½ï¼šè¯»å–ã€è§£æ Word æ–‡æ¡£ï¼Œæå–æ®µè½æ–‡æœ¬
"""

from pathlib import Path
from docx import Document
from typing import List, Dict

class WordProcessor:
    """Word æ–‡æ¡£å¤„ç†å™¨"""
    
    def __init__(self):
        pass
    
    def extract_paragraphs(self, docx_path: str) -> List[Dict]:
        """
        ä» Word æ–‡æ¡£æå–æ®µè½
        
        Args:
            docx_path: Word æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ®µè½åˆ—è¡¨ [{"index": 0, "text": "...", "style": "Normal"}]
        """
        doc = Document(docx_path)
        paragraphs = []
        
        for i, para in enumerate(doc.paragraphs):
            text = para.text.strip()
            if text:  # å¿½ç•¥ç©ºæ®µè½
                paragraphs.append({
                    "index": i,
                    "text": text,
                    "style": para.style.name if para.style else "Normal",
                    "is_heading": para.style and "Heading" in para.style.name
                })
        
        return paragraphs
    
    def extract_with_formatting(self, docx_path: str) -> List[Dict]:
        """
        æå–æ®µè½ï¼Œä¿ç•™æ›´å¤šæ ¼å¼ä¿¡æ¯ï¼ˆç”¨äºç²¾ç¡®åŒ¹é…ï¼‰
        """
        doc = Document(docx_path)
        paragraphs = []
        
        for i, para in enumerate(doc.paragraphs):
            text = para.text.strip()
            if not text:
                continue
            
            # æ£€æµ‹æ ¼å¼ç‰¹å¾
            is_bold = any(run.bold for run in para.runs if run.bold)
            is_italic = any(run.italic for run in para.runs if run.italic)
            
            paragraphs.append({
                "index": i,
                "text": text,
                "style": para.style.name if para.style else "Normal",
                "is_heading": para.style and "Heading" in para.style.name,
                "is_bold": is_bold,
                "is_italic": is_italic,
                "char_count": len(text)
            })
        
        return paragraphs


# æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
SUPPORTED_FORMATS = ['.docx', '.doc']

def is_supported_word_file(filepath: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„ Word æ–‡ä»¶æ ¼å¼"""
    return Path(filepath).suffix.lower() in SUPPORTED_FORMATS
```

### 3.2 æ–‡æœ¬å¯¹é½æ¨¡å— (`text_aligner.py`)

```python
"""
æ–‡æœ¬å¯¹é½æ¨¡å—
åŠŸèƒ½ï¼šå°† PDF åŸæ–‡æ®µè½ä¸ Word è¯‘æ–‡æ®µè½è¿›è¡Œå¯¹é½åŒ¹é…
"""

import re
from typing import List, Dict, Tuple
from difflib import SequenceMatcher

class TextAligner:
    """æ–‡æœ¬æ®µè½å¯¹é½å™¨"""
    
    def __init__(self, similarity_threshold: float = 0.3):
        """
        Args:
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è®¤ä¸ºä¸åŒ¹é…
        """
        self.similarity_threshold = similarity_threshold
    
    def align_paragraphs(
        self, 
        source_paragraphs: List[Dict],  # PDF åŸæ–‡æ®µè½
        target_paragraphs: List[Dict]   # Word è¯‘æ–‡æ®µè½
    ) -> List[Dict]:
        """
        å¯¹é½åŸæ–‡æ®µè½å’Œè¯‘æ–‡æ®µè½
        
        ç­–ç•¥ï¼š
        1. æŒ‰é¡ºåºåŒ¹é…ï¼ˆå‡è®¾è¯‘æ–‡é¡ºåºä¸åŸæ–‡ä¸€è‡´ï¼‰
        2. é€šè¿‡æ®µè½é•¿åº¦æ¯”ä¾‹è¿›è¡Œè¾…åŠ©åŒ¹é…
        3. æ ‡è®°æ— æ³•åŒ¹é…çš„æ®µè½
        
        Returns:
            å¯¹é½ç»“æœåˆ—è¡¨ [{
                "source_index": 0,
                "target_index": 0,
                "source_text": "åŸæ–‡...",
                "target_text": "è¯‘æ–‡...",
                "confidence": 0.85,
                "page": 1
            }]
        """
        aligned = []
        target_idx = 0
        
        for src_para in source_paragraphs:
            src_text = src_para.get("text", "")
            src_page = src_para.get("page", 1)
            src_idx = src_para.get("index", len(aligned))
            
            best_match = None
            best_confidence = 0
            
            # åœ¨å½“å‰ä½ç½®é™„è¿‘æœç´¢æœ€ä½³åŒ¹é…
            search_range = range(
                max(0, target_idx - 2),
                min(len(target_paragraphs), target_idx + 5)
            )
            
            for t_idx in search_range:
                if t_idx >= len(target_paragraphs):
                    break
                    
                tgt_para = target_paragraphs[t_idx]
                tgt_text = tgt_para.get("text", "")
                
                # è®¡ç®—åŒ¹é…ç½®ä¿¡åº¦
                confidence = self._calculate_match_confidence(src_text, tgt_text)
                
                if confidence > best_confidence:
                    best_confidence = confidence
                    best_match = {
                        "target_index": t_idx,
                        "target_text": tgt_text
                    }
            
            # è®°å½•å¯¹é½ç»“æœ
            if best_match and best_confidence >= self.similarity_threshold:
                aligned.append({
                    "source_index": src_idx,
                    "target_index": best_match["target_index"],
                    "source_text": src_text,
                    "target_text": best_match["target_text"],
                    "confidence": best_confidence,
                    "page": src_page,
                    "matched": True
                })
                target_idx = best_match["target_index"] + 1
            else:
                # æ— æ³•åŒ¹é…ï¼Œæ ‡è®°ä¸ºä»…æœ‰åŸæ–‡
                aligned.append({
                    "source_index": src_idx,
                    "target_index": None,
                    "source_text": src_text,
                    "target_text": None,
                    "confidence": 0,
                    "page": src_page,
                    "matched": False
                })
        
        return aligned
    
    def _calculate_match_confidence(self, source: str, target: str) -> float:
        """
        è®¡ç®—æºæ–‡æœ¬å’Œç›®æ ‡æ–‡æœ¬çš„åŒ¹é…ç½®ä¿¡åº¦
        
        è€ƒè™‘å› ç´ ï¼š
        1. é•¿åº¦æ¯”ä¾‹ï¼ˆè¯‘æ–‡é€šå¸¸æ¯”åŸæ–‡çŸ­30%-50%ï¼‰
        2. æ®µè½ä½ç½®ï¼ˆå‡è®¾é¡ºåºä¸€è‡´ï¼‰
        3. ç‰¹æ®Šæ ‡è®°ï¼ˆå¦‚æ•°å­—ã€ä¸“æœ‰åè¯ï¼‰
        """
        if not source or not target:
            return 0.0
        
        # 1. é•¿åº¦æ¯”ä¾‹åˆ†æ•°
        src_len = len(source)
        tgt_len = len(target)
        
        # æ³•è¯‘ä¸­çš„åˆç†é•¿åº¦æ¯”ä¾‹ï¼š0.3 - 0.8
        ratio = tgt_len / src_len if src_len > 0 else 0
        length_score = 1.0 if 0.3 <= ratio <= 0.9 else max(0, 1 - abs(ratio - 0.6))
        
        # 2. æ•°å­—åŒ¹é…åˆ†æ•°
        src_numbers = set(re.findall(r'\d+', source))
        tgt_numbers = set(re.findall(r'\d+', target))
        if src_numbers:
            number_score = len(src_numbers & tgt_numbers) / len(src_numbers)
        else:
            number_score = 1.0
        
        # 3. æ ‡ç‚¹å¯†åº¦åŒ¹é…ï¼ˆæ®µè½ç»“æ„ç›¸ä¼¼æ€§ï¼‰
        src_punct = len(re.findall(r'[.,;:!?]', source))
        tgt_punct = len(re.findall(r'[ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ]', target))
        punct_ratio = min(src_punct, tgt_punct) / max(src_punct, tgt_punct, 1)
        punct_score = punct_ratio if punct_ratio > 0.3 else 0.5
        
        # ç»¼åˆå¾—åˆ†
        confidence = (length_score * 0.4 + number_score * 0.4 + punct_score * 0.2)
        
        return confidence
    
    def merge_short_paragraphs(
        self, 
        paragraphs: List[Dict], 
        min_length: int = 50
    ) -> List[Dict]:
        """
        åˆå¹¶è¿‡çŸ­çš„æ®µè½ï¼ˆå¯èƒ½æ˜¯è¢«é”™è¯¯åˆ†å‰²çš„ï¼‰
        """
        merged = []
        buffer = None
        
        for para in paragraphs:
            if buffer is None:
                buffer = para.copy()
            elif len(buffer["text"]) < min_length:
                # åˆå¹¶åˆ° buffer
                buffer["text"] += "\n" + para["text"]
            else:
                merged.append(buffer)
                buffer = para.copy()
        
        if buffer:
            merged.append(buffer)
        
        return merged
```

### 3.3 ç¼–è¾‘æœåŠ¡æ ¸å¿ƒæ¨¡å— (`editor_service.py`)

```python
"""
ç¼–è¾‘æœåŠ¡æ ¸å¿ƒæ¨¡å—
åŠŸèƒ½ï¼šæ•´åˆç¿»è¯‘ä¸ç¼–è¾‘å®¡æ ¡åŠŸèƒ½ï¼Œæ‰“ç£¨ç”¨æˆ·è¯‘æ–‡
"""

import os
import json
import time
import threading
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Optional

from openai import OpenAI
from dotenv import load_dotenv

from word_processor import WordProcessor
from text_aligner import TextAligner
from multi_model_translator import MultiModelTranslator

load_dotenv()


class EditorService:
    """ç¼–è¾‘æœåŠ¡ - å¯¹æ¯”ã€è¯„å®¡ã€æ‰“ç£¨è¯‘æ–‡"""
    
    # ç¼–è¾‘å®¡æ ¡é»˜è®¤æç¤ºè¯
    DEFAULT_EDITOR_PROMPT = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç¿»è¯‘ç¼–è¾‘ï¼ŒåŒæ—¶ç²¾é€šæ³•è¯­å’Œä¸­æ–‡ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„å‡ºç‰ˆç¼–è¾‘ç»éªŒã€‚

ä½ å°†æ”¶åˆ°ï¼š
1. æ³•è¯­åŸæ–‡
2. ç”¨æˆ·è‡ªå·±çš„ä¸­æ–‡è¯‘æ–‡ï¼ˆåˆç¨¿ï¼‰
3. å¤šä¸ª AI æ¨¡å‹çš„ç¿»è¯‘ç‰ˆæœ¬

## ä½ çš„è§’è‰²

ä½ åŒæ—¶æ‹…ä»»ä¸¤ä¸ªè§’è‰²ï¼š

### è§’è‰²1ï¼šç¿»è¯‘è€…
- ç‹¬ç«‹ç†è§£åŸæ–‡ï¼Œåˆ¤æ–­å„è¯‘æ–‡çš„å‡†ç¡®æ€§
- è¯†åˆ«ç¿»è¯‘ä¸­çš„é”™è¯¯ï¼ˆæ¼è¯‘ã€è¯¯è¯‘ã€è¿‡è¯‘ï¼‰

### è§’è‰²2ï¼šä¸¥å‰çš„ç¼–è¾‘
- ä»¥å‡ºç‰ˆæ ‡å‡†å®¡è§†è¯‘æ–‡è´¨é‡
- æ£€æŸ¥æœ¯è¯­å‡†ç¡®æ€§ã€è¡Œæ–‡æµç•…åº¦ã€é£æ ¼ä¸€è‡´æ€§
- ç»™å‡ºå…·ä½“çš„ä¿®æ”¹å»ºè®®

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰

```
[è¯„å®¡æ„è§]
å¯¹ç”¨æˆ·è¯‘æ–‡çš„ç®€è¦è¯„ä»·ï¼š
- ä¼˜ç‚¹ï¼šï¼ˆ1-2 å¥ï¼‰
- é—®é¢˜ï¼šï¼ˆåˆ—å‡ºä¸»è¦é—®é¢˜ï¼‰
- å‚è€ƒä»·å€¼ï¼šè¯´æ˜ä» AI è¯‘æ–‡ä¸­å€Ÿé‰´äº†ä»€ä¹ˆ

[æœ€ç»ˆè¯‘æ–‡]
æ‰“ç£¨åçš„æœ€ä½³è¯‘æ–‡
```

## ç¼–è¾‘åŸåˆ™

1. **å¿ å®åŸæ–‡**ï¼šä¸å¾—æ“…è‡ªå¢åˆ å†…å®¹
2. **å°Šé‡ä½œè€…**ï¼šä¿ç•™ç”¨æˆ·è¯‘æ–‡çš„ä¼˜ç§€è¡¨è¾¾
3. **å–é•¿è¡¥çŸ­**ï¼šç»¼åˆå„ç‰ˆæœ¬ä¼˜ç‚¹
4. **ç²¾ç›Šæ±‚ç²¾**ï¼šæ¯ä¸ªè¯è¯­éƒ½è¦åå¤æ¨æ•²
5. **æœ¯è¯­ä¸€è‡´**ï¼šä¿æŒä¸“ä¸šæœ¯è¯­ç¿»è¯‘çš„ä¸€è‡´æ€§
"""

    # ç¿»è¯‘å¯¹æ¯”æç¤ºè¯
    TRANSLATION_COMPARE_PROMPT = """ä½ æ˜¯ä¸€ä½ç²¾é€šæ³•è¯­å’Œä¸­æ–‡çš„ä¸“ä¸šç¿»è¯‘å®˜ã€‚
è¯·å°†ä»¥ä¸‹æ³•è¯­æ–‡æœ¬ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚

è¦æ±‚ï¼š
1. å‡†ç¡®ä¼ è¾¾åŸæ„ï¼Œè¯­è¨€æµç•…è‡ªç„¶
2. ä¿æŒå­¦æœ¯æ€§/æ–‡å­¦æ€§é£æ ¼
3. ä¸“ä¸šæœ¯è¯­åå¯åŠ æ‹¬å·æ ‡æ³¨åŸæ–‡
4. ç›´æ¥è¿”å›è¯‘æ–‡ï¼Œä¸è¦è§£é‡Š
"""

    def __init__(
        self,
        api_key: str = None,
        base_url: str = None,
        translation_models: List[str] = None,
        editor_model: str = None,
        editor_prompt: str = None,
        translation_prompts: List[str] = None,
        output_dir: str = "output"
    ):
        """
        åˆå§‹åŒ–ç¼–è¾‘æœåŠ¡
        
        Args:
            api_key: API å¯†é’¥
            base_url: API åŸºç¡€ URL
            translation_models: ç”¨äºå¯¹æ¯”ç¿»è¯‘çš„æ¨¡å‹åˆ—è¡¨
            editor_model: ç”¨äºç¼–è¾‘å®¡æ ¡çš„æ¨¡å‹
            editor_prompt: è‡ªå®šä¹‰ç¼–è¾‘æç¤ºè¯
            translation_prompts: æ¯ä¸ªç¿»è¯‘æ¨¡å‹çš„æç¤ºè¯
            output_dir: è¾“å‡ºç›®å½•
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.base_url = base_url or os.getenv("OPENAI_BASE_URL")
        
        self.translation_models = translation_models or [
            "x-ai/grok-4.1-fast",
            "anthropic/claude-sonnet-4",
            "deepseek/deepseek-chat"
        ]
        self.editor_model = editor_model or "anthropic/claude-sonnet-4"
        
        self.editor_prompt = editor_prompt or self.DEFAULT_EDITOR_PROMPT
        self.translation_prompts = translation_prompts or \
            [self.TRANSLATION_COMPARE_PROMPT] * len(self.translation_models)
        
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ– API å®¢æˆ·ç«¯
        client_kwargs = {"api_key": self.api_key}
        if self.base_url:
            client_kwargs["base_url"] = self.base_url
        self.client = OpenAI(**client_kwargs)
        
        # åˆå§‹åŒ–å­æ¨¡å—
        self.word_processor = WordProcessor()
        self.text_aligner = TextAligner()
    
    def _call_model(
        self, 
        model: str, 
        system_prompt: str, 
        user_content: str,
        max_retries: int = 3
    ) -> str:
        """è°ƒç”¨æ¨¡å‹ API"""
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_content}
                    ],
                    temperature=0.3,
                    max_tokens=4000
                )
                result = response.choices[0].message.content
                if result and result.strip():
                    return result.strip()
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)
                else:
                    raise e
        return ""

    def translate_for_comparison(self, source_text: str) -> Dict[str, str]:
        """
        è°ƒç”¨å¤šä¸ªæ¨¡å‹ç¿»è¯‘ï¼Œç”¨äºå¯¹æ¯”
        
        Returns:
            {model_name: translation}
        """
        translations = {}
        
        with ThreadPoolExecutor(max_workers=len(self.translation_models)) as executor:
            futures = {}
            for idx, model in enumerate(self.translation_models):
                prompt = self.translation_prompts[idx] if idx < len(self.translation_prompts) \
                    else self.TRANSLATION_COMPARE_PROMPT
                future = executor.submit(
                    self._call_model, 
                    model, 
                    prompt, 
                    f"è¯·ç¿»è¯‘ï¼š\n\n{source_text}"
                )
                futures[future] = f"{idx+1}_{model}"
            
            for future in as_completed(futures):
                key = futures[future]
                try:
                    translations[key] = future.result()
                except Exception as e:
                    translations[key] = f"[ç¿»è¯‘å¤±è´¥: {str(e)}]"
        
        return translations
    
    def edit_paragraph(
        self, 
        source_text: str,           # åŸæ–‡
        user_translation: str,      # ç”¨æˆ·è¯‘æ–‡
        ai_translations: Dict[str, str] = None  # AI å¯¹æ¯”è¯‘æ–‡ï¼ˆå¯é€‰ï¼‰
    ) -> Dict:
        """
        ç¼–è¾‘å®¡æ ¡å•ä¸ªæ®µè½
        
        Args:
            source_text: æ³•è¯­åŸæ–‡
            user_translation: ç”¨æˆ·çš„è¯‘æ–‡
            ai_translations: AI ç¿»è¯‘ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼Œè‹¥æ— åˆ™è°ƒç”¨è·å–ï¼‰
            
        Returns:
            {
                "review": "è¯„å®¡æ„è§",
                "final": "æœ€ç»ˆè¯‘æ–‡",
                "ai_translations": {...}
            }
        """
        # å¦‚æœæ²¡æœ‰ AI è¯‘æ–‡ï¼Œå…ˆè·å–
        if ai_translations is None:
            ai_translations = self.translate_for_comparison(source_text)
        
        # æ„å»ºç¼–è¾‘è¯·æ±‚
        user_content = f"""## æ³•è¯­åŸæ–‡

{source_text}

## ç”¨æˆ·è¯‘æ–‡ï¼ˆå¾…å®¡æ ¡ï¼‰

{user_translation}

## AI å‚è€ƒè¯‘æ–‡

"""
        for model, trans in sorted(ai_translations.items()):
            model_short = model.split("/")[-1] if "/" in model else model
            user_content += f"### {model_short}\n{trans}\n\n"
        
        user_content += "## è¯·æŒ‰æ ¼å¼è¾“å‡ºè¯„å®¡æ„è§å’Œæœ€ç»ˆè¯‘æ–‡"
        
        # è°ƒç”¨ç¼–è¾‘æ¨¡å‹
        result = self._call_model(self.editor_model, self.editor_prompt, user_content)
        
        # è§£æç»“æœ
        review = ""
        final_text = result
        
        if "[è¯„å®¡æ„è§]" in result and "[æœ€ç»ˆè¯‘æ–‡]" in result:
            parts = result.split("[æœ€ç»ˆè¯‘æ–‡]")
            if len(parts) == 2:
                review = parts[0].replace("[è¯„å®¡æ„è§]", "").strip()
                final_text = parts[1].strip()
        
        return {
            "source": source_text,
            "user_translation": user_translation,
            "ai_translations": ai_translations,
            "review": review,
            "final": final_text
        }
    
    def process_document(
        self,
        pdf_path: str,
        word_path: str,
        start_page: int = None,
        end_page: int = None,
        max_workers: int = 5,
        progress_callback = None
    ) -> Dict:
        """
        å¤„ç†å®Œæ•´æ–‡æ¡£ï¼šå¯¹é½ã€ç¿»è¯‘ã€ç¼–è¾‘
        
        Args:
            pdf_path: PDF åŸæ–‡è·¯å¾„
            word_path: Word è¯‘æ–‡è·¯å¾„
            start_page: èµ·å§‹é¡µç 
            end_page: ç»“æŸé¡µç 
            max_workers: å¹¶å‘æ•°
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            å¤„ç†ç»“æœ
        """
        results = {
            "paragraphs": [],
            "stats": {
                "total": 0,
                "matched": 0,
                "edited": 0
            }
        }
        
        # 1. æå– PDF åŸæ–‡
        from pdf_translator import PDFTranslator
        pdf_helper = PDFTranslator(api_key="dummy")
        pdf_pages = pdf_helper.extract_text_from_pdf(pdf_path)
        
        # ç­›é€‰é¡µé¢èŒƒå›´
        if start_page or end_page:
            pdf_pages = [
                p for p in pdf_pages
                if (start_page is None or p["page"] >= start_page) and
                   (end_page is None or p["page"] <= end_page)
            ]
        
        # è½¬æ¢ä¸ºæ®µè½åˆ—è¡¨
        pdf_paragraphs = []
        for page_data in pdf_pages:
            page_num = page_data["page"]
            text = page_data["text"]
            # æŒ‰æ®µè½åˆ†å‰²
            for para in text.split("\n\n"):
                para = para.strip()
                if para:
                    pdf_paragraphs.append({
                        "page": page_num,
                        "text": para,
                        "index": len(pdf_paragraphs)
                    })
        
        # 2. æå– Word è¯‘æ–‡
        word_paragraphs = self.word_processor.extract_paragraphs(word_path)
        
        # 3. å¯¹é½æ®µè½
        aligned = self.text_aligner.align_paragraphs(pdf_paragraphs, word_paragraphs)
        
        results["stats"]["total"] = len(aligned)
        results["stats"]["matched"] = sum(1 for a in aligned if a["matched"])
        
        # 4. å¹¶å‘å¤„ç†æ¯ä¸ªæ®µè½
        lock = threading.Lock()
        processed = 0
        
        def process_paragraph(item):
            nonlocal processed
            
            source_text = item["source_text"]
            user_trans = item["target_text"] if item["matched"] else None
            
            if user_trans:
                # æœ‰ç”¨æˆ·è¯‘æ–‡ï¼Œè¿›è¡Œç¼–è¾‘å®¡æ ¡
                edit_result = self.edit_paragraph(source_text, user_trans)
                result = {
                    **item,
                    "ai_translations": edit_result["ai_translations"],
                    "review": edit_result["review"],
                    "final": edit_result["final"],
                    "edited": True
                }
            else:
                # æ— ç”¨æˆ·è¯‘æ–‡ï¼Œä»…ç¿»è¯‘
                ai_trans = self.translate_for_comparison(source_text)
                # ä½¿ç”¨æ•´åˆæ¨¡å‹ç”Ÿæˆæœ€ç»ˆç‰ˆæœ¬
                best_trans = list(ai_trans.values())[0] if ai_trans else source_text
                result = {
                    **item,
                    "ai_translations": ai_trans,
                    "review": "[æ— å¯¹åº”ç”¨æˆ·è¯‘æ–‡ï¼Œä½¿ç”¨ AI ç¿»è¯‘]",
                    "final": best_trans,
                    "edited": False
                }
            
            with lock:
                processed += 1
                if progress_callback:
                    progress_callback(processed, len(aligned))
            
            return result
        
        # å¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(process_paragraph, item) for item in aligned]
            
            for future in as_completed(futures):
                try:
                    result = future.result()
                    results["paragraphs"].append(result)
                    if result.get("edited"):
                        results["stats"]["edited"] += 1
                except Exception as e:
                    print(f"å¤„ç†æ®µè½å¤±è´¥: {e}")
        
        # æŒ‰é¡µç å’Œç´¢å¼•æ’åº
        results["paragraphs"].sort(key=lambda x: (x.get("page", 0), x.get("source_index", 0)))
        
        return results
    
    def generate_output_files(self, results: Dict, base_name: str) -> Dict[str, str]:
        """
        ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
        
        Returns:
            {"final": path, "review": path, "comparison": path}
        """
        output_files = {}
        
        # 1. æœ€ç»ˆè¯‘æ–‡
        final_file = self.output_dir / f"{base_name}_edited_final.txt"
        with open(final_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("  ç¼–è¾‘æ‰“ç£¨åçš„æœ€ç»ˆè¯‘æ–‡\n")
            f.write("=" * 60 + "\n\n")
            
            current_page = None
            for para in results["paragraphs"]:
                page = para.get("page", 0)
                if page != current_page:
                    f.write(f"\nã€ç¬¬ {page} é¡µã€‘\n\n")
                    current_page = page
                
                f.write(para.get("final", "") + "\n\n")
        
        output_files["final"] = str(final_file)
        
        # 2. è¯„å®¡æŠ¥å‘Š
        review_file = self.output_dir / f"{base_name}_edit_review.txt"
        with open(review_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("  ç¼–è¾‘å®¡æ ¡æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"æ€»æ®µè½æ•°: {results['stats']['total']}\n")
            f.write(f"æˆåŠŸåŒ¹é…: {results['stats']['matched']}\n")
            f.write(f"å®Œæˆç¼–è¾‘: {results['stats']['edited']}\n\n")
            f.write("-" * 60 + "\n\n")
            
            for i, para in enumerate(results["paragraphs"], 1):
                f.write(f"ã€æ®µè½ {i}ã€‘ç¬¬ {para.get('page', 0)} é¡µ\n\n")
                f.write(f"åŸæ–‡: {para.get('source_text', '')[:100]}...\n\n")
                
                if para.get("target_text"):
                    f.write(f"ç”¨æˆ·è¯‘æ–‡: {para.get('target_text', '')[:100]}...\n\n")
                
                f.write(f"è¯„å®¡æ„è§:\n{para.get('review', '')}\n\n")
                f.write("-" * 40 + "\n\n")
        
        output_files["review"] = str(review_file)
        
        # 3. å®Œæ•´å¯¹ç…§
        comparison_file = self.output_dir / f"{base_name}_full_comparison.txt"
        with open(comparison_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("  å®Œæ•´ç¿»è¯‘å¯¹ç…§\n")
            f.write("=" * 60 + "\n\n")
            
            for i, para in enumerate(results["paragraphs"], 1):
                f.write(f"â•”{'â•' * 56}â•—\n")
                f.write(f"â•‘ æ®µè½ {i} - ç¬¬ {para.get('page', 0)} é¡µ\n")
                f.write(f"â•š{'â•' * 56}â•\n\n")
                
                f.write("ã€åŸæ–‡ã€‘\n")
                f.write(para.get("source_text", "") + "\n\n")
                
                if para.get("target_text"):
                    f.write("ã€ç”¨æˆ·è¯‘æ–‡ã€‘\n")
                    f.write(para.get("target_text", "") + "\n\n")
                
                f.write("ã€AI å‚è€ƒè¯‘æ–‡ã€‘\n")
                for model, trans in para.get("ai_translations", {}).items():
                    model_short = model.split("/")[-1] if "/" in model else model
                    f.write(f"- {model_short}:\n{trans}\n\n")
                
                f.write("ã€è¯„å®¡æ„è§ã€‘\n")
                f.write(para.get("review", "") + "\n\n")
                
                f.write("ã€æœ€ç»ˆè¯‘æ–‡ã€‘\n")
                f.write(para.get("final", "") + "\n\n")
                
                f.write("=" * 60 + "\n\n")
        
        output_files["comparison"] = str(comparison_file)
        
        return output_files
```

---

## 4. API è·¯ç”±è®¾è®¡

### 4.1 æ–°å¢ API ç«¯ç‚¹

åœ¨ `server.py` ä¸­æ–°å¢ä»¥ä¸‹è·¯ç”±ï¼š

```python
# ============================================
# Editor Mode Routes
# ============================================

@app.route('/api/editor/upload-word', methods=['POST'])
def upload_word():
    """ä¸Šä¼  Word è¯‘æ–‡æ–‡ä»¶"""
    if 'file' not in request.files:
        return jsonify({'error': 'æ²¡æœ‰æ–‡ä»¶'}), 400
    
    file = request.files['file']
    if not file.filename.lower().endswith(('.docx', '.doc')):
        return jsonify({'error': 'åªæ”¯æŒ Word æ–‡ä»¶ (.docx, .doc)'}), 400
    
    import uuid
    file_id = str(uuid.uuid4())[:8]
    filename = f"{file_id}_{file.filename}"
    filepath = UPLOAD_FOLDER / filename
    file.save(filepath)
    
    # æå–æ®µè½æ•°
    try:
        from word_processor import WordProcessor
        processor = WordProcessor()
        paragraphs = processor.extract_paragraphs(str(filepath))
        para_count = len(paragraphs)
    except Exception as e:
        return jsonify({'error': f'æ— æ³•è¯»å– Word æ–‡ä»¶: {str(e)}'}), 400
    
    return jsonify({
        'file_id': file_id,
        'filename': file.filename,
        'path': str(filepath),
        'paragraph_count': para_count
    })


@app.route('/api/editor/start', methods=['POST'])
def start_editor_task():
    """å¼€å§‹ç¼–è¾‘ä»»åŠ¡"""
    data = request.json
    
    pdf_path = data.get('pdf_path')
    word_path = data.get('word_path')
    
    if not pdf_path or not word_path:
        return jsonify({'error': 'ç¼ºå°‘ PDF æˆ– Word æ–‡ä»¶è·¯å¾„'}), 400
    
    import uuid
    task_id = str(uuid.uuid4())[:8]
    
    translation_tasks[task_id] = {
        'id': task_id,
        'type': 'editor',
        'status': 'pending',
        'progress': 0,
        'total_paragraphs': 0,
        'completed_paragraphs': 0,
        'results': None,
        'error': None,
        'created_at': datetime.now().isoformat()
    }
    
    # åå°çº¿ç¨‹è¿è¡Œ
    thread = threading.Thread(
        target=run_editor_task,
        args=(task_id, pdf_path, word_path, data)
    )
    thread.start()
    
    return jsonify({'task_id': task_id})


def run_editor_task(task_id: str, pdf_path: str, word_path: str, config: dict):
    """è¿è¡Œç¼–è¾‘ä»»åŠ¡"""
    try:
        task = translation_tasks[task_id]
        task['status'] = 'processing'
        
        from editor_service import EditorService
        
        editor = EditorService(
            translation_models=config.get('translation_models'),
            editor_model=config.get('editor_model'),
            editor_prompt=config.get('editor_prompt'),
            translation_prompts=config.get('translation_prompts')
        )
        
        def progress_callback(completed, total):
            task['completed_paragraphs'] = completed
            task['total_paragraphs'] = total
            task['progress'] = int(completed / total * 100) if total > 0 else 0
        
        results = editor.process_document(
            pdf_path=pdf_path,
            word_path=word_path,
            start_page=config.get('start_page'),
            end_page=config.get('end_page'),
            max_workers=config.get('workers', 5),
            progress_callback=progress_callback
        )
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
        from pathlib import Path
        base_name = Path(pdf_path).stem
        output_files = editor.generate_output_files(results, base_name)
        
        task['results'] = results
        task['output_files'] = output_files
        task['status'] = 'completed'
        task['completed_at'] = datetime.now().isoformat()
        
    except Exception as e:
        task = translation_tasks[task_id]
        task['status'] = 'error'
        task['error'] = str(e)
        import traceback
        traceback.print_exc()
```

---

## 5. å‰ç«¯ç•Œé¢è®¾è®¡

### 5.1 ç¼–è¾‘æ¨¡å¼é¡µé¢å¸ƒå±€

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PDF ç¿»è¯‘å·¥å…·                    [Flash] [High] [Editor]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚                     â”‚  â”‚                     â”‚          â”‚
â”‚  â”‚   ä¸Šä¼  PDF åŸæ–‡      â”‚  â”‚   ä¸Šä¼  Word è¯‘æ–‡    â”‚          â”‚
â”‚  â”‚      ğŸ“„             â”‚  â”‚      ğŸ“            â”‚          â”‚
â”‚  â”‚                     â”‚  â”‚                     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  é…ç½®é€‰é¡¹                                            â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  ç¿»è¯‘æ¨¡å‹:  [+ æ·»åŠ æ¨¡å‹]                             â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚   â”‚
â”‚  â”‚    â”‚ grok-4.1-fast  â”‚  â”‚ claude-sonnet  â”‚  [åˆ é™¤]   â”‚   â”‚
â”‚  â”‚    â”‚ [ç¼–è¾‘æç¤ºè¯]    â”‚  â”‚ [ç¼–è¾‘æç¤ºè¯]    â”‚           â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  ç¼–è¾‘æ¨¡å‹:  [claude-sonnet-4 â–¼]                      â”‚   â”‚
â”‚  â”‚    [ç¼–è¾‘å®¡æ ¡æç¤ºè¯]                                   â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  é¡µé¢èŒƒå›´:  [1] - [å…¨éƒ¨]    å¹¶å‘æ•°: [5]              â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚              [å¼€å§‹ç¼–è¾‘æ‰“ç£¨]                                  â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è¿›åº¦: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 65%  (26/40 æ®µè½)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚      åŸæ–‡ & ç”¨æˆ·è¯‘æ–‡    â”‚     ç¼–è¾‘ç»“æœ          â”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚                       â”‚                       â”‚         â”‚
â”‚  â”‚  ã€åŸæ–‡ã€‘              â”‚  ã€è¯„å®¡æ„è§ã€‘          â”‚         â”‚
â”‚  â”‚  Il est important...  â”‚  ç”¨æˆ·è¯‘æ–‡æ•´ä½“å‡†ç¡®...   â”‚         â”‚
â”‚  â”‚                       â”‚                       â”‚         â”‚
â”‚  â”‚  ã€ç”¨æˆ·è¯‘æ–‡ã€‘          â”‚  ã€æœ€ç»ˆè¯‘æ–‡ã€‘          â”‚         â”‚
â”‚  â”‚  é‡è¦çš„æ˜¯...          â”‚  é‡è¦çš„æ˜¯è¦ç†è§£...    â”‚         â”‚
â”‚  â”‚                       â”‚                       â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                             â”‚
â”‚  [ä¸‹è½½æœ€ç»ˆè¯‘æ–‡] [ä¸‹è½½è¯„å®¡æŠ¥å‘Š] [ä¸‹è½½å®Œæ•´å¯¹ç…§]                â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 å‰ç«¯äº¤äº’æµç¨‹

```
1. ç”¨æˆ·é€‰æ‹© "Editor" æ¨¡å¼
           â”‚
           â–¼
2. ä¸Šä¼  PDF åŸæ–‡ & Word è¯‘æ–‡
           â”‚
           â–¼
3. é…ç½®ç¿»è¯‘æ¨¡å‹å’Œç¼–è¾‘æ¨¡å‹
   - å¯æ·»åŠ /åˆ é™¤ç¿»è¯‘æ¨¡å‹
   - æ¯ä¸ªæ¨¡å‹å¯è®¾ç½®ç‹¬ç«‹æç¤ºè¯
   - å¯è‡ªå®šä¹‰ç¼–è¾‘å®¡æ ¡æç¤ºè¯
           â”‚
           â–¼
4. ç‚¹å‡» "å¼€å§‹ç¼–è¾‘æ‰“ç£¨"
           â”‚
           â–¼
5. å®æ—¶æ˜¾ç¤ºè¿›åº¦
   - å½“å‰å¤„ç†æ®µè½
   - è¿›åº¦ç™¾åˆ†æ¯”
           â”‚
           â–¼
6. å®Œæˆåæ˜¾ç¤ºç»“æœ
   - å·¦ä¾§ï¼šåŸæ–‡ + ç”¨æˆ·è¯‘æ–‡
   - å³ä¾§ï¼šè¯„å®¡æ„è§ + æœ€ç»ˆè¯‘æ–‡
   - å¯ç¿»é¡µæŸ¥çœ‹æ¯ä¸ªæ®µè½
           â”‚
           â–¼
7. ä¸‹è½½è¾“å‡ºæ–‡ä»¶
   - æœ€ç»ˆè¯‘æ–‡ (TXT/MD/PDF)
   - è¯„å®¡æŠ¥å‘Š
   - å®Œæ•´å¯¹ç…§
```

---

## 6. æç¤ºè¯é…ç½®

### 6.1 ç¿»è¯‘å¯¹æ¯”æç¤ºè¯ï¼ˆå¯è‡ªå®šä¹‰ï¼‰

```
ä½ æ˜¯ä¸€ä½ç²¾é€šæ³•è¯­å’Œä¸­æ–‡çš„ä¸“ä¸šç¿»è¯‘å®˜ã€‚
è¯·å°†ä»¥ä¸‹æ³•è¯­æ–‡æœ¬ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚

è¦æ±‚ï¼š
1. å‡†ç¡®ä¼ è¾¾åŸæ„ï¼Œè¯­è¨€æµç•…è‡ªç„¶
2. ä¿æŒå­¦æœ¯æ€§/æ–‡å­¦æ€§é£æ ¼
3. ä¸“ä¸šæœ¯è¯­åå¯åŠ æ‹¬å·æ ‡æ³¨åŸæ–‡
4. ç›´æ¥è¿”å›è¯‘æ–‡ï¼Œä¸è¦è§£é‡Š
```

### 6.2 ç¼–è¾‘å®¡æ ¡æç¤ºè¯ï¼ˆå¯è‡ªå®šä¹‰ï¼‰

```
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç¿»è¯‘ç¼–è¾‘ï¼ŒåŒæ—¶ç²¾é€šæ³•è¯­å’Œä¸­æ–‡ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„å‡ºç‰ˆç¼–è¾‘ç»éªŒã€‚

ä½ å°†æ”¶åˆ°ï¼š
1. æ³•è¯­åŸæ–‡
2. ç”¨æˆ·è‡ªå·±çš„ä¸­æ–‡è¯‘æ–‡ï¼ˆåˆç¨¿ï¼‰
3. å¤šä¸ª AI æ¨¡å‹çš„ç¿»è¯‘ç‰ˆæœ¬

## ä½ çš„è§’è‰²

### è§’è‰²1ï¼šç¿»è¯‘è€…
- ç‹¬ç«‹ç†è§£åŸæ–‡ï¼Œåˆ¤æ–­å„è¯‘æ–‡çš„å‡†ç¡®æ€§
- è¯†åˆ«ç¿»è¯‘ä¸­çš„é”™è¯¯ï¼ˆæ¼è¯‘ã€è¯¯è¯‘ã€è¿‡è¯‘ï¼‰

### è§’è‰²2ï¼šä¸¥å‰çš„ç¼–è¾‘
- ä»¥å‡ºç‰ˆæ ‡å‡†å®¡è§†è¯‘æ–‡è´¨é‡
- æ£€æŸ¥æœ¯è¯­å‡†ç¡®æ€§ã€è¡Œæ–‡æµç•…åº¦ã€é£æ ¼ä¸€è‡´æ€§
- ç»™å‡ºå…·ä½“çš„ä¿®æ”¹å»ºè®®

## è¾“å‡ºæ ¼å¼

[è¯„å®¡æ„è§]
å¯¹ç”¨æˆ·è¯‘æ–‡çš„ç®€è¦è¯„ä»·ï¼š
- ä¼˜ç‚¹ï¼šï¼ˆ1-2 å¥ï¼‰
- é—®é¢˜ï¼šï¼ˆåˆ—å‡ºä¸»è¦é—®é¢˜ï¼‰
- å‚è€ƒä»·å€¼ï¼šè¯´æ˜ä» AI è¯‘æ–‡ä¸­å€Ÿé‰´äº†ä»€ä¹ˆ

[æœ€ç»ˆè¯‘æ–‡]
æ‰“ç£¨åçš„æœ€ä½³è¯‘æ–‡

## ç¼–è¾‘åŸåˆ™

1. å¿ å®åŸæ–‡ï¼šä¸å¾—æ“…è‡ªå¢åˆ å†…å®¹
2. å°Šé‡ä½œè€…ï¼šä¿ç•™ç”¨æˆ·è¯‘æ–‡çš„ä¼˜ç§€è¡¨è¾¾
3. å–é•¿è¡¥çŸ­ï¼šç»¼åˆå„ç‰ˆæœ¬ä¼˜ç‚¹
4. ç²¾ç›Šæ±‚ç²¾ï¼šæ¯ä¸ªè¯è¯­éƒ½è¦åå¤æ¨æ•²
5. æœ¯è¯­ä¸€è‡´ï¼šä¿æŒä¸“ä¸šæœ¯è¯­ç¿»è¯‘çš„ä¸€è‡´æ€§
```

---

## 7. ä¾èµ–é¡¹

æ–°å¢ä»¥ä¸‹ Python åŒ…ï¼š

```txt
# requirements.txt æ–°å¢
python-docx>=0.8.11    # Word æ–‡æ¡£å¤„ç†
```

---

## 8. å¼€å‘è®¡åˆ’

### Phase 1: æ ¸å¿ƒæ¨¡å—å¼€å‘
- [ ] `word_processor.py` - Word æ–‡æ¡£è§£æ
- [ ] `text_aligner.py` - æ®µè½å¯¹é½ç®—æ³•
- [ ] `editor_service.py` - ç¼–è¾‘æœåŠ¡æ ¸å¿ƒ

### Phase 2: åç«¯é›†æˆ
- [ ] æ–°å¢ API è·¯ç”±
- [ ] ç¼–è¾‘ä»»åŠ¡ç®¡ç†
- [ ] è¾“å‡ºæ–‡ä»¶ç”Ÿæˆ

### Phase 3: å‰ç«¯å¼€å‘
- [ ] ç¼–è¾‘æ¨¡å¼ UI
- [ ] æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
- [ ] ç»“æœå±•ç¤ºç»„ä»¶
- [ ] æç¤ºè¯ç¼–è¾‘å™¨

### Phase 4: æµ‹è¯•ä¼˜åŒ–
- [ ] æ®µè½å¯¹é½å‡†ç¡®æ€§æµ‹è¯•
- [ ] å¤§æ–‡æ¡£æ€§èƒ½ä¼˜åŒ–
- [ ] ç”¨æˆ·ä½“éªŒä¼˜åŒ–

---

## 9. æ³¨æ„äº‹é¡¹

1. **æ®µè½å¯¹é½æ˜¯å…³é”®**
   - æ³•è¯‘ä¸­é•¿åº¦å˜åŒ–å¤§ï¼Œå¯¹é½ç®—æ³•éœ€è¦è°ƒä¼˜
   - å»ºè®®æä¾›æ‰‹åŠ¨è°ƒæ•´å¯¹é½çš„åŠŸèƒ½

2. **ä¿æŒæ¨¡å—ç‹¬ç«‹**
   - ç¼–è¾‘åŠŸèƒ½åº”ä½œä¸ºç‹¬ç«‹æ¨¡å—ï¼Œä¸å½±å“ç°æœ‰ç¿»è¯‘åŠŸèƒ½
   - å¤ç”¨ç°æœ‰çš„ `multi_model_translator.py`

3. **æç¤ºè¯å¯é…ç½®**
   - æ¯ä¸ªæ­¥éª¤éƒ½æ”¯æŒè‡ªå®šä¹‰æç¤ºè¯
   - æä¾›åˆç†çš„é»˜è®¤å€¼

4. **è¿›åº¦ä¿å­˜**
   - æ”¯æŒæ–­ç‚¹ç»­ä¼ 
   - ä¿å­˜ä¸­é—´ç»“æœ

5. **è¾“å‡ºæ ¼å¼**
   - æ”¯æŒ TXT/MD/PDF å¤šç§æ ¼å¼
   - ä¿ç•™è¯„å®¡ä¿®æ”¹ç—•è¿¹
